\documentclass[letter-paper]{tufte-book}

%%
% Book metadata
\title{Analysis 3H}
\author[]{B. S. H. Mithrandir}
%\publisher{Research Institute of Valinor}

%%
% If they're installed, use Bergamo and Chantilly from www.fontsite.com.
% They're clones of Bembo and Gill Sans, respectively.
\IfFileExists{bergamo.sty}{\usepackage[osf]{bergamo}}{}% Bembo
\IfFileExists{chantill.sty}{\usepackage{chantill}}{}% Gill Sans

%\usepackage{microtype}
\usepackage{amssymb}
\usepackage{amsmath}
%%
% For nicely typeset tabular material
\usepackage{booktabs}

%% overunder braces
\usepackage{oubraces}

%% 
\usepackage{xcolor}
\usepackage{tcolorbox}

\newtcolorbox[auto counter,number within=section]{derivbox}[2][]{colback=TealBlue!5!white,colframe=TealBlue,title=Box \thetcbcounter:\ #2,#1}                                                          

\makeatletter
\@openrightfalse
\makeatother

%%
% For graphics / images
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{figs/}}

\usepackage{tikz-cd}

% The fancyvrb package lets us customize the formatting of verbatim
% environments.  We use a slightly smaller font.
\usepackage{fancyvrb}
\fvset{fontsize=\normalsize}

\usepackage[plain]{fancyref}
\newcommand*{\fancyrefboxlabelprefix}{box}
\fancyrefaddcaptions{english}{%
  \providecommand*{\frefboxname}{Box}%
  \providecommand*{\Frefboxname}{Box}%
}
\frefformat{plain}{\fancyrefboxlabelprefix}{\frefboxname\fancyrefdefaultspacing#1}
\Frefformat{plain}{\fancyrefboxlabelprefix}{\Frefboxname\fancyrefdefaultspacing#1}

%%
% Prints argument within hanging parentheses (i.e., parentheses that take
% up no horizontal space).  Useful in tabular environments.
\newcommand{\hangp}[1]{\makebox[0pt][r]{(}#1\makebox[0pt][l]{)}}

%% 
% Prints an asterisk that takes up no horizontal space.
% Useful in tabular environments.
\newcommand{\hangstar}{\makebox[0pt][l]{*}}

%%
% Prints a trailing space in a smart way.
\usepackage{xspace}
\usepackage{xstring}

%%
% Some shortcuts for Tufte's book titles.  The lowercase commands will
% produce the initials of the book title in italics.  The all-caps commands
% will print out the full title of the book in italics.
\newcommand{\vdqi}{\textit{VDQI}\xspace}
\newcommand{\ei}{\textit{EI}\xspace}
\newcommand{\ve}{\textit{VE}\xspace}
\newcommand{\be}{\textit{BE}\xspace}
\newcommand{\VDQI}{\textit{The Visual Display of Quantitative Information}\xspace}
\newcommand{\EI}{\textit{Envisioning Information}\xspace}
\newcommand{\VE}{\textit{Visual Explanations}\xspace}
\newcommand{\BE}{\textit{Beautiful Evidence}\xspace}

\newcommand{\TL}{Tufte-\LaTeX\xspace}

% Prints the month name (e.g., January) and the year (e.g., 2008)
\newcommand{\monthyear}{%
  \ifcase\month\or January\or February\or March\or April\or May\or June\or
  July\or August\or September\or October\or November\or
  December\fi\space\number\year
}


\newcommand{\urlwhitespacereplace}[1]{\StrSubstitute{#1}{ }{_}[\wpLink]}

\newcommand{\wikipedialink}[1]{http://en.wikipedia.org/wiki/#1}% needs \wpLink now

\newcommand{\anonymouswikipedialink}[1]{\urlwhitespacereplace{#1}\href{\wikipedialink{\wpLink}}{Wikipedia}}

\newcommand{\Wikiref}[1]{\urlwhitespacereplace{#1}\href{\wikipedialink{\wpLink}}{#1}}

% Prints an epigraph and speaker in sans serif, all-caps type.
\newcommand{\openepigraph}[2]{%
  %\sffamily\fontsize{14}{16}\selectfont
  \begin{fullwidth}
  \sffamily\large
  \begin{doublespace}
  \noindent\allcaps{#1}\\% epigraph
  \noindent\allcaps{#2}% author
  \end{doublespace}
  \end{fullwidth}
}

% Inserts a blank page
\newcommand{\blankpage}{\newpage\hbox{}\thispagestyle{empty}\newpage}

\usepackage{units}

% Typesets the font size, leading, and measure in the form of 10/12x26 pc.
\newcommand{\measure}[3]{#1/#2$\times$\unit[#3]{pc}}

% Macros for typesetting the documentation
\newcommand{\hlred}[1]{\textcolor{Maroon}{#1}}% prints in red
\newcommand{\hangleft}[1]{\makebox[0pt][r]{#1}}
\newcommand{\hairsp}{\hspace{1pt}}% hair space
\newcommand{\hquad}{\hskip0.5em\relax}% half quad space
\newcommand{\TODO}{\textcolor{red}{\bf TODO!}\xspace}
\newcommand{\na}{\quad--}% used in tables for N/A cells
\providecommand{\XeLaTeX}{X\lower.5ex\hbox{\kern-0.15em\reflectbox{E}}\kern-0.1em\LaTeX}
\newcommand{\tXeLaTeX}{\XeLaTeX\index{XeLaTeX@\protect\XeLaTeX}}
% \index{\texttt{\textbackslash xyz}@\hangleft{\texttt{\textbackslash}}\texttt{xyz}}
\newcommand{\tuftebs}{\symbol{'134}}% a backslash in tt type in OT1/T1
\newcommand{\doccmdnoindex}[2][]{\texttt{\tuftebs#2}}% command name -- adds backslash automatically (and doesn't add cmd to the index)
\newcommand{\doccmddef}[2][]{%
  \hlred{\texttt{\tuftebs#2}}\label{cmd:#2}%
  \ifthenelse{\isempty{#1}}%
    {% add the command to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2}}% command name
    }%
    {% add the command and package to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2} (\texttt{#1} package)}% command name
      \index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}% package name
    }%
}% command name -- adds backslash automatically
\newcommand{\doccmd}[2][]{%
  \texttt{\tuftebs#2}%
  \ifthenelse{\isempty{#1}}%
    {% add the command to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2}}% command name
    }%
    {% add the command and package to the index
      \index{#2 command@\protect\hangleft{\texttt{\tuftebs}}\texttt{#2} (\texttt{#1} package)}% command name
      \index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}% package name
    }%
}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newenvironment{docspec}{\begin{quotation}\ttfamily\parskip0pt\parindent0pt\ignorespaces}{\end{quotation}}% command specification environment
\newcommand{\docenv}[1]{\texttt{#1}\index{#1 environment@\texttt{#1} environment}\index{environments!#1@\texttt{#1}}}% environment name
\newcommand{\docenvdef}[1]{\hlred{\texttt{#1}}\label{env:#1}\index{#1 environment@\texttt{#1} environment}\index{environments!#1@\texttt{#1}}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}\index{#1 package@\texttt{#1} package}\index{packages!#1@\texttt{#1}}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}\index{#1 class option@\texttt{#1} class option}\index{class options!#1@\texttt{#1}}}% document class option name
\newcommand{\docclsoptdef}[1]{\hlred{\texttt{#1}}\label{clsopt:#1}\index{#1 class option@\texttt{#1} class option}\index{class options!#1@\texttt{#1}}}% document class option name defined
\newcommand{\docmsg}[2]{\bigskip\begin{fullwidth}\noindent\ttfamily#1\end{fullwidth}\medskip\par\noindent#2}
\newcommand{\docfilehook}[2]{\texttt{#1}\index{file hooks!#2}\index{#1@\texttt{#1}}}
\newcommand{\doccounter}[1]{\texttt{#1}\index{#1 counter@\texttt{#1} counter}}

\newcommand{\studyq}[1]{\marginnote{Q: #1}}

\hypersetup{colorlinks}% uncomment this line if you prefer colored hyperlinks (e.g., for onscreen viewing)

% Generates the index
\usepackage{makeidx}
\makeindex

\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% custom commands

\newtheorem{theorem}{\color{pastel-blue}Theorem}[section]
\newtheorem{lemma}[theorem]{\color{pastel-blue}Lemma}
\newtheorem{proposition}[theorem]{\color{pastel-blue}Proposition}
\newtheorem{corollary}[theorem]{\color{pastel-blue}Corollary}

\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\hyphenpenalty=5000

% more pastel ones
\xdefinecolor{pastel-red}{rgb}{0.77,0.31,0.32}
\xdefinecolor{pastel-green}{rgb}{0.33,0.66,0.41}
\definecolor{pastel-blue}{rgb}{0.30,0.45,0.69} % crayola blue
\definecolor{gray}{rgb}{0.2,0.2,0.2} % dark gray

\xdefinecolor{orange}{rgb}{1,0.45,0}
\xdefinecolor{green}{rgb}{0,0.35,0}
\definecolor{blue}{rgb}{0.12,0.46,0.99} % crayola blue
\definecolor{gray}{rgb}{0.2,0.2,0.2} % dark gray

\xdefinecolor{cerulean}{rgb}{0.01,0.48,0.65}
\xdefinecolor{ust-blue}{rgb}{0,0.20,0.47}
\xdefinecolor{ust-mustard}{rgb}{0.67,0.52,0.13}

%\newcommand\comment[1]{{\color{red}#1}}

\newcommand{\dy}{\partial}
\newcommand{\ddy}[2]{\frac{\dy#1}{\dy#2}}

\newcommand{\ex}{\mathrm{e}}
\newcommand{\zi}{{\rm i}}

\newcommand\Real{\mbox{Re}} % cf plain TeX's \Re and Reynolds number
\newcommand\Imag{\mbox{Im}} % cf plain TeX's \Im

\newcommand\Def[1]{\textbf{#1}}

\newcommand{\qed}{\hfill$\blacksquare$}
\newcommand{\qedwhite}{\hfill \ensuremath{\Box}}

\newcommand{\highlight}[1]{\mathchoice%
  {\colorbox{black!10}{$\displaystyle#1$}}%
  {\colorbox{black!10}{$\textstyle#1$}}%
  {\colorbox{black!10}{$\scriptstyle#1$}}%
  {\colorbox{black!10}{$\scriptscriptstyle#1$}}}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% some extra formatting (hacked from Patrick Farrell's notes)
%  https://courses.maths.ox.ac.uk/node/view_material/4915
%

% chapter format
\titleformat{\chapter}%
  {\huge\rmfamily\itshape\color{pastel-red}}% format applied to label+text
  {\llap{\colorbox{pastel-red}{\parbox{1.5cm}{\hfill\itshape\huge\color{white}\thechapter}}}}% label
  {1em}% horizontal separation between label and title body
  {}% before the title body
  []% after the title body

% section format
\titleformat{\section}%
  {\normalfont\Large\itshape\color{pastel-green}}% format applied to label+text
  {\llap{\colorbox{pastel-green}{\parbox{1.5cm}{\hfill\color{white}\thesection}}}}% label
  {1em}% horizontal separation between label and title body
  {}% before the title body
  []% after the title body

% subsection format
\titleformat{\subsection}%
  {\normalfont\large\itshape\color{pastel-blue}}% format applied to label+text
  {\llap{\colorbox{pastel-blue}{\parbox{1.5cm}{\hfill\color{white}\thesubsection}}}}% label
  {1em}% horizontal separation between label and title body
  {}% before the title body
  []% after the title body

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

% Front matter
%\frontmatter

% r.3 full title page
%\maketitle

% v.4 copyright page

\chapter*{}

\begin{fullwidth}

\par \begin{center}{\Huge Analysis 3H}\end{center}

\vspace*{5mm}

\par \begin{center}{\Large typed up by B. S. H. Mithrandir}\end{center}

\vspace*{5mm}

\begin{itemize}
  \item \textit{Last compiled: \monthyear}
  \item Adapted from notes of D. Sch\"utz, Durham
  \item This was part of the Analysis 3H module elective. This is a course on
  real analysis, touching on metric spaces, tangent spaces, vector fields,
  manifolds, and differential forms.
  \item[]
  \item \TODO diagrams, notation (bold vs not bold), highlighting of important bits, probably unbold things (to have $k$-forms and vectors agreeing in notation)
\end{itemize}

\par

\par Licensed under the Apache License, Version 2.0 (the ``License''); you may not
use this file except in compliance with the License. You may obtain a copy
of the License at \url{http://www.apache.org/licenses/LICENSE-2.0}. Unless
required by applicable law or agreed to in writing, software distributed
under the License is distributed on an \smallcaps{``AS IS'' BASIS, WITHOUT
WARRANTIES OR CONDITIONS OF ANY KIND}, either express or implied. See the
License for the specific language governing permissions and limitations
under the License.
\end{fullwidth}


%===============================================================================

\chapter{Metric spaces}

%-------------------------------------------------------------------------------

\section{Basic notions}

The field of real numbers $\mathbb{R}$ is a totally ordered field which also
satisfies the \textbf{completeness} axiom, i.e. a non-empty bounded set $A
\subseteq \mathbb{R}$ has a \textbf{supremum} and/or an \textbf{infimum}. The
supremum of $A\subseteq\mathbb{R}$ is a real number $s$ where $a\leq s$ for all
$a\in A$. If $m$ is also such that $a \leq m$ for $a \in A$, then $s\leq m$,
denoted $\sup A$. The infimum of $A$ is where the inequalities signs are
swapped, denoted $\inf A$.

\begin{lemma}\label{lem:intervals}
  Let $I_n = [a_n, b_n]$ be a sequence of closed intervals such that $a_n \leq
  a_{n+1} < b_{n+1} \leq b_n$ for all $n\geq 1$, then $\cap_{n=1}^\infty I_n$ is
  non-empty. \qedwhite
\end{lemma}

\begin{proof}
  Let $a = \sup\{ a_n \}$. Since $a_n \leq b_1$ for all $n$ exists by
  completeness axiom, $a_n \leq b_k$ for any value of $n$ and $k$, and so $a\leq
  b_k$. Hence $a_k \leq a \leq b_k$ for all $k$, and that $a \in
  \cap_{n=1}^\infty I_n$.
\end{proof}

Let $M$ be a set. A function $d : M\times M \to [0, \infty)$ is called a
\textbf{metric} on $M$ if
\begin{enumerate}
  \item $d(x, y) = 0$ iff $x = y$;
  \item $d(x, y) = d(y, x)$ for all $x,y\in M$;
  \item $d(x, z) \leq d(x, y) + d(y, z)$ for all $x, y, z \in M$.
\end{enumerate}
The pair $(M, d)$ is then called a \textbf{metric space}. It is easy to see
any $N\subseteq M$ is also a metric space using the same $d$.

\begin{example}
  \begin{enumerate}
    \item On $\mathbb{R}$, $d(x,y) = |y - x|$ gives a metric.
    \item On $\mathbb{R}^2$, $d_1 (x, y) = |y_1 - x_1| + |y_2 - x_2|$ is also a
    metric, but notice that, for example, $d_1( (1, 1), (0, 0) ) = 2$ as opposed
    to the expected distance of $\sqrt{2}$.
  \end{enumerate}
\end{example}

The standard (Euclidean) metric in $\mathbb{R}^2$ is given by\marginnote{We will
not be distinguishing vectors by bold quantities in this document.}
\begin{equation*}
  d(x, y) = \sqrt{|x_1 - y_1|^2 + |x_2 - y_2|^2}.
\end{equation*}

Let $V$ be a real vector space. An \textbf{inner product} on $V$ is a function
$(\cdot, \cdot) : V\times V\to \mathbb{R}$ that, for all $x, y \in V$, satisfies
the following:
\begin{itemize}
  \item linearity in the first factor;
  \item $(x, y) = (y, x)$;
  \item $(x, x) \geq 0$ and is zero iff $x = 0$.
\end{itemize}
\begin{example}
  \begin{enumerate}
    \item For $V = \mathbb{R}^n$, the standard inner product is given by $(x, y)
    = x_i y_i$ (where Einstein notation is understood). If $A$ is a symmetric
    matrix, then $(x, y) = x^T A y$ is an inner product if all eigenvalues of
    $A$ are positive.
    
    \item For $V = C[a, b]$, $(f, g) = \int_a^b f(x) g(x)\, \mathrm{d}x$ is an
    inner product since $V$ is a vector space of continuous functions, and the
    only function that is everywhere zero and continuous is $f(x) = 0$ for all
    $x\in[a, b]$.
  \end{enumerate}
\end{example}

\begin{theorem}[Cauchy--Schwartz inequality]
  Let $V$ be a real vector space, and $(\cdot, \cdot)$ an inner product on $V$.
  Then
  \begin{equation*}
    \left|(x, y)\right| \leq \|x\| \cdot \|y\|,
  \end{equation*}
  where $\|\cdot\|$ is the standard Euclidean norm of the vector, and there is
  equality iff $x = \lambda y$ for some $\lambda \in \mathbb{R}$.
\end{theorem}

\begin{proof}
  Note that $(x, 0) = (x, x - x) = (x, x) - (x, x) =
  0$, so we may assume that $y \neq 0$. Then, with
  $\lambda = -(x, y) / \|y\|^2$,
  \begin{align*}
    0 \leq (x + \lambda y, x + \lambda y) 
      & = \| x \|^2 + 2\lambda(x, y) + \lambda^2 \| y \|^2\\
      & = \| x \|^2 - \frac{(x, y)^2}{\| y \|^2}.
  \end{align*}
  So $(x, y)^2 \leq \| x \|^2 \| y \|^2$ and the result follows. \qed
\end{proof}

\begin{lemma}
  Let $V$ be a real vector space with inner product $(\cdot, \cdot)$. Then $d: V
  \times V \to [0, \infty)$ with $d(x, y) = \| x - y\|$ gives a metric on $V$.
\end{lemma}

\begin{proof}
  Clearly $d(x, x) = 0$ and is symmetric, so we just need to check the triangle
  inequality. By Cauchy--Schwartz,
  \begin{align*}
    \| a + b\| &= \sqrt{\|a\|^2 + 2(a, b) + \| b\|^2} \\
      &\leq \sqrt{\|a\|^2 + 2\|a\| \|b\| + \| b\|^2} \\
      &\leq \|a\| + \|b\|,
  \end{align*}
  as required. \qed
\end{proof}

Let $f: M \to N$ be a function metric metric spaces $(M, d_M)$ and $(N, d_N)$.
For $a \in M$, $f$ is \textbf{continuous at $a$} if, for all $\epsilon > 0$,
there exists $\delta >0$ such that $d_N(f(a), f(x)) < \epsilon$ for all $x\in M$
when $d_M(a, x) < \delta$.

%-------------------------------------------------------------------------------

\section{Sequences and Cauchy sequences}

Let $M$ be a metric space. A \textbf{sequence} $(a_n)$ in $M$ consists of
elements $a_n \in M$ for all $n\in\mathbb{N}$. Let $a \in M$, and $(a_n)$
\textbf{converges to $a$} if, for all $\epsilon > 0$, $d(a_n, a) < \epsilon$
for some all $n \geq n_0$. We write $\lim_{n\to\infty} a_n = a$. The sequence
$(a_n)$ is called \textbf{convergent} if there exists $a\in M$ where $a_n \to
a$.

\begin{lemma}
  Let $f : M \to N$ be a function between metric spaces and $a \in M$. The
  function $f$ is continuous at $a \in M$ iff $f(a_n) \to f(a)$ for $(a_n) \in
  M$ with $a_n \to a$. (Note that $f(a_n)$ is a sequence in $N$.)
\end{lemma}

\begin{proof}
  Assume that $f$ is continuous at $a \in M$, and let $(a_n)$ be a sequence with
  $a_n \to a$. By continuity, for any $\epsilon > 0$, there exists $\delta > 0$
  such that, for $d(a, y) < \delta$, $d(f(a), f(y)) <\epsilon$ for arbitrary $y
  \in M$. Choose $n_0 \geq 0$ such that $d(a_n, a) < \delta$ for all $n\geq
  n_0$, then this implies $d(f(a_n), f(a)) < \epsilon$, and thus $f(a_n) \to
  f(a)$ as required.
  
  On the other hand, assume $f(a_n) \to f(a)$ for all sequences such that $a_n
  \to a$. Given $\epsilon > 0$, assume that instead there is no $\delta > 0$
  such that, for $d(a, y) < \delta$, $d(f(a), f(y)) <\epsilon$ for arbitrary $y
  \in M$. Then we can find $a_n \in M$ with $d(a, a_n) < 1/n$. However, this
  means $d(f(a), f(a_n)) \geq \epsilon$, which contradicts the assumption that
  $f(a_n) \to f(a)$ even though $a_n \to a$. So such $\delta$ exists and we have
  continuity. \qed
\end{proof}

\begin{lemma}
  The limit of a sequence is unique.
\end{lemma}

\begin{proof}
  Assume there are two limits $a$ and $b$ for the sequence $a_n$. Then $d(a,b)
  \leq d(a, a_n) + d(a_n, b)$. As $n\to\infty$, the RHS tends to zero so $a =
  b$. \qed
\end{proof}

A \textbf{Cauchy sequence} $(a_n)$ in the metric space $M$ is a sequence such
that, for all $\epsilon > 0$, there exists $n_0 \geq 0$ such that $d(a_p, a_q) <
\epsilon$ for all $p, q \geq n_0$.

\begin{lemma}
  A convergent sequence is a Cauchy sequence (the converse is not true).
\end{lemma}

\begin{proof}
  Suppose $a_n \to a$. Then, for all $\epsilon > 0$, there is some $n_0 \geq 0$
  such that $d(a_n, a) < \epsilon / 2$ for $n \geq n_0$. Let $p, q \geq n_0$,
  then $d(a_n, a_q) \leq d(a_p, a) + d(a_q, a) < \epsilon$, so the sequence is
  Cauchy. \qed
\end{proof}

A metric space $M$ is \textbf{complete} if all Cauchy sequences in $M$
converges.
\begin{theorem}
  The real line $\mathbb{R}$ is complete.
\end{theorem}

\begin{proof}
  Let $(a_n)$ be a Cauchy sequence in $\mathbb{R}$. Define the sequence of
  integers $(n_k)$ where $n_0 = 1$, and $n_{k+1}$ is the smallest integer bigger
  than $n_k$ where $| a_p - a_q | < 2^{-(k+2)}$ for $p, q \geq n_{k+1}$. Define
  the intervals $I_k = [a_{n_k} - 2^{-k}, a_{n_k} + 2^{-k}]$ and let $x \in
  I_{k+1}$. Now, since $x \in I_{k+1}$, this implies that $|x - a_{n_{k+1}}| <
  2^{-(k+1)}$. By definition of the integer sequence, $|a_{n_{k}} - a_{n_{k+1}}|
  < 2^{-(k+1)}$, so then, by triangle inequality,
  \begin{equation*}
    |a_{n_k} - x| \leq |x - a_{n_{k+1}}| + |a_{n_{k+1}} - a_{n_k}| < 
      2 \cdot 2^{-(k+1)} = 2^{-k},  
  \end{equation*}
  so $x \in I_k$. However, $x \in I_{k+1}$, so $I_{k+1} \subset I_k$. By
  Lemma~\ref{lem:intervals}, $\cap_{k=1}^\infty I_k \neq \emptyset$, so assume
  $a \in \cap_{k=1}^\infty I_k$. For $m \geq n_k$,
  \begin{equation*}
    |a - a_m| \leq |a - a_{n_k}| + |a_{n_k} - a_m| \leq 2^{-k} + 2^{-(k+1)}
    \to 0
  \end{equation*}
  as $m \geq n_k \to \infty$. Thus $a_m \to a$ and this arbitrary Cauchy
  sequence converges in $\mathbb{R}$ and thus $\mathbb{R}$ is complete. \qed
\end{proof}

\begin{proposition}
  For $X \neq \emptyset$, let $\mathcal{B}(X)$ be the set of functions $f : X
  \to \mathbb{R}$ such that $f$ is bounded. For $f, g, \in \mathcal{B}(X)$, let
  $d(f, g) = \sup_{x\in X} |f(x) - g(x)$. Then $(\mathcal{B}(X), d(f,g))$
  defines a complete metric space.
\end{proposition}

\begin{proof}
  $d$ is clearly a metric. For completeness, let $(f_n)$ be a Cauchy sequence in
  $\mathcal{B}(X)$. For $x\in X$, $(f_n(x))$ is a Cauchy sequence of real
  numbers because, by definition of $d(f,g)$, $|f_q(x) - f_p(x)| \leq d(f_p -
  f_q)$, and since $\mathcal{R}$ is complete, the sequence $(f_n(x))$ converges.
  
  Defining $f: X\to\mathbb{R}$ such that $f(x) = \lim_{n\to\infty} f_n(x)$, we
  need to show that $f\in\mathcal{B}(X)$, and that indeed $f_n(x) \to f(x)$
  regardless of $x\in X$. Be definition of a Cauchy sequence, for $\epsilon >0$,
  there exists $n_0 \geq 0$ such that $d(f_p, f_q) < \epsilon / 2$ for $p, q
  \geq n_0$. Note also that, for all $x\in X$, there exists $n_1(x) \geq n_0$
  such that $|f_{n_1(x)} - f| < \epsilon / 2$. Then, let $x_\in X$ and $n \geq
  n_0$, we have
  \begin{equation*}
    |f_n(x) - f(x)| \leq |f_n - f_{n_1(x)}| + |f_{n_1(x)} - f| < \epsilon.
  \end{equation*}
  Additionally note, $|f(x)| \leq |f(x) - f_{n_0(x)}| + |f_{n_0(x)}| \leq
  \epsilon + c_{f_{n_0}}$ since $f_{n_0(x)}$ is bounded, so $f \in
  \mathcal{B}(X)$. Further, $d(f_n - f) = \sup |f_n - f| = \delta < \epsilon$,
  so $f_n$ converges to $f \in \mathcal{B}(x)$. Thus every Cauchy sequence
  converges and thus the space is complete and equipped with a metric. \qed
\end{proof}

%-------------------------------------------------------------------------------

\section{Topology of metric spaces}

Let $(M, d)$ be a metric space with $x \in M$ and $r > 0$. Define the
\textbf{open ball} around $x$ of radius $r$ to be
\begin{equation*}
  B(x; r) = \{ y \in M\ : \ d(x, y) < r\}.
\end{equation*}
The analogous \textbf{closed ball} $D(x; r)$ is defined with the less than or
equal to sign. A set $A \subset M$ is \textbf{bounded} if it can be contained in
some $D(x; r)$ for some $x \in M$, $r > 0$. A set $U \subset M$ is
\textbf{open} if, for all $x \in U$, there exists $r_{x} > 0$ such that
$B(x; r_{x}) \subset U$. A set $A \subset M$ is \textbf{closed} if $M
\setminus A$ is open.

\begin{lemma}
Let $(M, d)$ be a metric space, then:
  \begin{enumerate}
    \item $M$ and $\emptyset$ are open;
    \item $\bigcup_i A_i$ is open if all $A_i \subset M$ are open;
    \item $\bigcap_i^n$ is open if all $A_i \subset M$ are open and $n <
    \infty$;
    \item $B(x; r)$ is open for some $r > 0$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  The first two are obvious. For 3), suppose the open sets $U_i$ indexed by $i$
  are open and $x \in \bigcap_{i=1}^n U_i$. Then $x in U_i$ for all $i$, so
  there is some $B(x; r_i) \subset U_i$. Taking the minimum of such $r_i > 0$
  means $B(x; r_i) \subset \bigcap_{i=1}^n U_i$, and thus the collective
  finite union is open.
  
  For 4), let $y \in B(x; r)$, $r_y = r - d(x, y) > 0$ and $z \in
  B(y; r_y)$. Then $d(x, z) \leq d(x, y) + d(y, z) < d(x, y) +
  r - d(x, y) = r$, so $B(y; r_y) \subseteq B(x; r)$. \qed
\end{proof}

\begin{corollary}
The following may be shown by considering the appropriate complements:
  \begin{enumerate}
    \item $M$ and $\emptyset$ are closed;
    \item $\bigcap_i A_i$ is closed if $A_i \subset M$ for all $i$;
    \item $\bigcup_i A_i$ is closed if $A_i \subset M$ for all $i$ and $n <
    \infty$;
    \item $D(x; r)$ is closed.
  \end{enumerate}
  \qedwhite
\end{corollary}

\begin{example}
  Open intervals are open and closed intervals are closed.
  
  $(a, \infty)$ is open as it is a union of open bounded intervals.
  
  $[a, \infty)$ is closed since $(-\infty, a)$ is open.
  
  $\mathbb{Z}$ is closed as $\mathbb{R} \setminus \left(\cup_{n=-\infty}^\infty
  (n, n+1)\right)$ is closed.
  
  $\mathbb{Q}$ and $[0, 1)$ are neither, while $\mathbb{R}$ is both.
\end{example}

\begin{proposition}
  Suppose $M$ is a metric space and $A \subseteq M$. $A$ is closed iff every
  sequence converges to $a \in A$.
\end{proposition}

\begin{proof}
  Assume $A$ is closed and $a_n \to a$. Assume the converse so that $a \in U = M
  \setminus A$ which is an open set. Then there is some $r > 0$ such that $B(a;
  r) \in U$, and since $a_n \to a$, there exists $n_0 \geq 0$ where $d(a_n, a) <
  r$ for $n \geq n_0$. This implies $a_n \in B(a; r)$ for all $n$, but this is a
  contradiction since $a_n \in A$, and thus $a \in A$.
  
  Assume $a_n \to a \in A$. Let $x \in M\setminus A$, $r > 0$, and assume there
  is no such $B(x; r) \subset M\setminus A$. Thus there is an intersection,
  i.e., $B(x; 1/n) \cap A \neq \emptyset$. This implies that there is some $i$
  where $a_i \in B(x; 1/n) \cap A$. However, $(a_n)$ is a sequence in $A$ and
  $d(a_m, x) < 1/n$ for $m \geq n+1$, so $a_m \to a$, but this implies $x = a$
  which is not possible since $x \in M\setminus A$. So $M\setminus A$ is open
  which means $A$ is closed. \qed
\end{proof}

\begin{theorem}
  Let $M$ be a complete metric space and $A\subseteq M$ is closed. Then $A$ is
  complete with the induced metric.
\end{theorem}

\begin{proof}
  Let $(a_n)$ be a Cauchy sequence in $A$. Since $M$ is complete, $(a_n)$
  converges in $M$, but $A$ is closed, so $(a_n)$ converges in $A$ by previous
  proposition, which implies $A$ is complete. \qed
\end{proof}

Let $M$ be a metric space. $M$ is \textbf{compact} if every sequence $(a_n) \in
M$ has a convergent subsequence $(a_{n_k})$.
\begin{example}
  \begin{itemize}
    \item $(a_n) = (-1)^n$ is non-convergent but has a convergent sequence.
    
    \item $M = (0, 1)$ is not compact since $a_n = 1/n$ and its subsequences do
    not converge in $M$.
    
    \item $\mathbb{R}$ is not compact as $a_n$ has no subsequence converging in
    $\mathbb{R}$.
    
    \item $M = [0, 1]$ is compact. Let $(a_n)$ be a subsequence in $M$. Let
    $I_1$ be either $[0, 1/2]$ or $[1/2, 1]$, and let $(a_{n_k})$ be the
    subsequences in $I_1$. Continuing this we have a sequence of intervals
    $I_{m+1} \subset I_m$ with $I_m$ of length $2^{-m}$. Denote the subsequences
    $(a_{m_k}^m)$ to be those in $I_m$. Taking $b_m = a_{n_m}^m \in I_m$, we see
    that $b_{m+1} \in I_M$ since $I_{m+1} \subset I_m$, so that $d(b_m, b_q)
    \leq 2^{-m}$ for $q \geq m$. Thus $(b_m)$ is a Cauchy sequence, which is a
    subsequence of $(a_n)$. Since $M \subseteq \mathbb{R}$, $M$ is complete, so
    $b_m \to b \in M$, and thus $M$ is compact.
  \end{itemize}
\end{example}

\begin{proposition}
  By extension, closed $n$-gons in $\mathbb{R}^n$ are compact. \qedwhite
\end{proposition}

\begin{proposition}
  Let $f : M \to N$ be a continuous map between metric spaces. If $M$ is
  compact, then $f(M) \subset N$ is compact.
\end{proposition}

\begin{proof}
  Let $(a_n)$ be a sequence in $f(M)$. Then $a_n = f(b_n)$ for some $b_n \in M$.
  The sequence $(b_{n_k})$ converges in $M$ since $M$ is compact, thus
  \begin{equation*}
    \lim_{k\to\infty} a_{n_k} = \lim_{k\to\infty} f(b_{n_k})
    = f \left(\lim_{k\to\infty} b_{n_k} \right) = f(b)
  \end{equation*}
  since $f$ is continuous. So $(a_{n_k})$ is convergent, thus $f(M)$ is compact.
  \qedwhite
\end{proof}

\begin{proposition}
  A closed subset of a compact space is a compact set.
\end{proposition}

\begin{proof}
  Let $(a_n)$ be a sequence in $A \subset M$ where $M$ is compact. Since $(a_n)
  \in M$, $(a_{n_k})$ is convergent, but $A$ closed so $(a_{n_k}) \to a \in A$,
  thus $A$ is compact. \qedwhite
\end{proof}

\subsection{Heine--Borel theorem}

\begin{theorem}
  A subset $A \subseteq \mathbb{R}^n$ is compact iff $A$ is closed and bounded.
\end{theorem}

\begin{proof}
  Suppose $A$ is compact, so clearly $A$ is closed. If $A$ is unbounded, then
  there exists $(a_n) \in A$ where $d(a_n, 0) \geq n$, so $(a_{n_k})$ does not
  converge in $\mathbb{R}^n$. However $A$ is compact, which is a contradiction,
  so $A$ is bounded.
  
  Suppose $A$ is bounded, then $A\subseteq [a,b]^n$. If $A$ is closed, then it
  is a closed subset of a compact set, so $A$ is compact by previous
  proposition. \qed
\end{proof}

For example, if $f: M \to N$ with $f$ is a scalar continuous function, then
$f(M) \subset \mathbb{R}$ is closed and bounded since $M$ is compact, and thus
$f(M)$ compact implies $f(M)$ is closed and bounded.

%-------------------------------------------------------------------------------

\section{Banach and Hilbert spaces}

Let $V$ be a real vector space. The \textbf{norm} on $V$ is a function
$\|\cdot\| : V \to [0, \infty)$ where:
\begin{enumerate}
  \item $\|x\| = 0$ iff $x = 0$;
  \item $\|\lambda x \| = |\lambda| \cdot \|x\|$ for all $x \in V$ and
  $\lambda \in \mathbb{R}$;
  \item $\|x + y\| \leq \|x\| + \|y\|$.
\end{enumerate}
The pair $\left(V, \| \cdot \|\right)$ gives a \textbf{normed vector space}.

\begin{lemma}
  Let $V$ be a normed vector space, then $d(x, y) = \|x - y\|$ defines a metric
  on $V$.
\end{lemma}

\begin{proof}
  Two of the properties follow from definition. To show the reflexive property,
  note that
  \begin{equation*}
    d(y, x) = \| y - x \| = \| (-1)(x - y)\| = \| x - y \| = d(x, y).
  \end{equation*}
  \qed
\end{proof}

\begin{example}
  \begin{enumerate}
    \item It may be shown that the metrics
    \begin{equation*}
      \sum_i |x_i|, \qquad \sum_i \sqrt{|x_i|^2}, \qquad
      \max \{|x_i| \in \mathbb{R}\}
    \end{equation*}
    define norms on $\mathbb{R}^n$ (the $\ell^1$, $\ell^2$ and $\ell^\infty$
    norms).
    
    \item The \textbf{supremum norm} on $B(X)$ is defined by
    \begin{equation*}
      \|f\|_{\infty} = \sup\{ |f(x)|\in \mathbb{R}\ ;\ x\in X\}.
    \end{equation*}
    
    \item For $X$ a metric space, $C_b (X) = \{f : x \to \mathbb{R}\ : \ f\
    \textnormal{continuous and bounded}\}$ is also a normed vector space with
    the supremum norm.
  \end{enumerate}
\end{example}

If $C(X) = \{f : x \to \mathbb{R}\ : \ f\ \textnormal{continuous}\}$ then $f$
does not have a supremum, however, we have the following:
\begin{proposition}
  If $X$ is compact, then $C(X) = C_b(X)$, so $C(X)$ is a normed vector space.
\end{proposition}

\begin{proof}
  $C_b(X) \subseteq C(X)$ regardless of $X$. For the converse, assume $f \in
  C(X)$, so that $f(X)$ is compact. This implies $f(X)$ is bounded and closed by
  the Heine--Borel theorem, so $C(X) \subseteq C_b(X)$. \qed
\end{proof}

Let $(V, \|\cdot\|_V)$ and $(W, \|\cdot\|_W)$ be two normed vector spaces. A
function $f : V \to W$ is continuous at $x \in V$ if, for all $\epsilon > 0$,
there exists $\delta > 0$ such that $\| x - y\|_V < \delta$ implies that $\|f(x)
- f(y)\|_W < \epsilon$.

Let $V$ be a normed vector space. $V$ is a \textbf{Banach space} if $V$ with
the metric induced by the norm is complete.

\begin{theorem}
  Let $X$ be a metric space, then $C_b(X)$ with the supremum norm is a Banach
  space.
\end{theorem}

\begin{proof}
  Since $C_b(X) \subseteq B(X)$, if $C_b$ is closed, then $C_b$ is complete
  since $B(X)$ is complete. To show this, let $(f_n) \in C_b(X)$, and let $f_n
  \to f \in B(X)$. The convergene of $f_n$ implies that there exists $n_0 \geq
  0$ such that $\|f_n - f\| < \epsilon /3$ for any $\epsilon > 0$ with $n \geq
  n_0$. Also, $\|f_{n_0}(y) - f(y)\| < \epsilon /3$ for all $y \in X$. The
  functions are continuous, so there exists $\delta > 0$ where, if $d(x, y) <
  \delta$, $\|f_{n_0}(x) - f_{n_0}(y)\| < \epsilon /3$ for $x \in X$. Thus, for
  $d(x, y) < \delta$,
  \begin{equation*}
    |f(x) - f(y)| \leq |f(x) - f_{n_0}(x)| + |f_{n_0}(x) - f_{n_0}(y)|
      + |f_{n_0}(y) - f(y)| < \epsilon,
  \end{equation*}
  so $f$ is continuous, and $C_b(X)$ is closed and thus complete. \qed
\end{proof}

\begin{corollary}
  For $a < b$, $C[a,b]$ with the supremum norm is a Banach space. \qedwhite
\end{corollary}

Note that $C[a,b]$ is not a complete space with, for example, the $L_2$ norm
\begin{equation*}
  \| f \|_2 = \sqrt{\int_a^b \left(f(x)\right)^2\, \mathrm{d}x}.
\end{equation*}
For example, with $f_n = x^n$, $f_n \to 0$ but clearly $f_n(1) = 1$ for all $n$.
The underlying reason is the sequence is not a Cauchy sequence with respect to
the norm.

Convergence with respect to the supremum norm is called \textbf{uniform
convergence} (cf. Complex Analysis 2H).

Let $(V, \|\cdot\|)$ be a Banach space. If there is an inner product from $V$
which induces this norm, then $V$ is called a \textbf{Hilbert space}.

\begin{theorem}
  Let $(M, d)$ be a metric space. Then there exists $(\overline{M},
  \overline{d})$ where $\overline{M}$ is complete, and there is an embedding
  $\iota : M \to \overline{M}$ with $d(x,y) = d(\iota(x), \iota(y))$ for all $x,
  y \in M$. Also, for all $\overline{x} \in \overline{M}$, there is a sequence
  $(x_n) \in M$ with $x_n \to \overline{x}$ as $n \to \infty$. \qedwhite
\end{theorem}

Here, $\overline{M}$ is called the \textbf{completion} of $M$, and it is unique
up to some isomorphism.

\begin{example}
  The completion of $\mathbb{Q}$ is $\mathbb{R}$ with respect to the Euclidean
  metric.
  
  The completeness of $C[a,b]$ with respect to the inner product metric is
  denoted $L^2[a,b]$.\marginnote{Note that elements of $L^2$ are not exactly
  functions, but rather \emph{equivalence classes} (cf. $11 \equiv 1$ modulo
  10)}.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The contraction mapping theorem}

\begin{theorem}
  Let $(M,d)$ be a complete metric space, $0\leq\lambda\leq1$ and a $f: M\to M$
  with $d(f(x), f(y)) \leq \lambda d(x,y)$ for all $x,y\in M$. Then $f$ has one
  unique fixed point where $f(x_0) = x_0$.\marginnote{Or, if you throw a map of
  the world on the floor, there is exactly one point on the map that exactly
  corresponds to one point on the floor.}
\end{theorem}

\begin{proof}
  Note that $f$ is a contraction, and continuity is automatically satisfied from
  the condition that $d(f(x), f(y)) \leq \lambda d(x,y)$.
  
  Let $x\in M$, and $a_n = f^n(x)$. So we have
  \begin{align*}
    d(x, a_n) &\leq d(x, f(x)) + d(f(x), f^2(x)) + \ldots d(f^{n-1}(x), f^n(x)) \\
      &= \sum_{i=0}^{n-1} d(f^i(x), f^{i+1}(x))\\
      &\leq \sum_{i=0}^{n-1} \lambda d(x, f(x))\\
      &= d(x, f(x)) \frac{1-\lambda^n}{1 - \lambda}\\
      &\leq \frac{d(x, f(x))}{1 - \lambda},
  \end{align*}
  by Cauchy--Schwartz and the arithmetic progression with $0\leq\lambda< 1$.
  Now,
  \begin{equation*}
    d(a_n, a_m) = d(f^n(x), f^m(x)) \leq \lambda^m d(f^{n-m}, x) \leq \lambda^m \frac{d(x, f(x))}{1-\lambda}
  \end{equation*}
  assuming $n>m$. For $n,m \geq n_0$, we have
  \begin{equation*}
    d(a_n, a_m) \leq \lambda^{n_0} \frac{d(x, f(x))}{1-\lambda}.
  \end{equation*}
  Clearly $(a_n)$ is a Cauchy sequence, and thus we have completeness and $a_n
  \to a \in M$. Now,
  \begin{equation*}
    f(a) = f\left(\lim_{n\to\infty} a_n\right) = \lim_{n\to\infty} f(a_n) = \lim_{n\to\infty} a_{n+1} = a,
  \end{equation*}
  so there is some $a\in M$ that is a fixed point.
  
  To show uniqueness, suppose $b$ is another fixed point. Then
  \begin{equation*}
    d(a,b) = d(f(a), f(b)) \leq \lambda d(a,b),
  \end{equation*}
  and for $\lambda \neq 0$, $d(a,b)=0$, so $a=b$. \qed
\end{proof}

%-------------------------------------------------------------------------------

\section{A norm for matrix spaces}

We want a norm reflecting the fact that matrices can be identified with linear
maps. Let $A = (A_{ij}) \in M_{n,k}(\mathbb{R})$. We define
\begin{equation}
  \| A \| = \sup \{ \|Ax\|_2 \ : \ x \in \mathbb{R}^k,\ \|x\|_2 \leq 1\},
\end{equation}
where $\|\cdot\|$ is the Euclidean norm. Here, $Ax \in \mathbb{R}^n$, and $x
\mapsto \|Ax\|_2$ is clearly a continuous map. By the Heine--Borel theorem, $\{
\|Ax\|_2\ : \ \|x\|_2 \leq 1\}$ is bounded and closed, so the supremum exists, and
there is $x$ with $\|x\|_2 \leq 1$ such that $\| A \| = \|Ax\|_2$ exists.

\begin{lemma}
  We have
  \begin{itemize}
    \item $\|Ax\|_2 \leq \|A\| \|x\|_2$ for all $A$ and $x$

    \item $\|AB\| \leq \|A\|\|B\|$
    
    \item $\|A\|_\infty \leq \|A\| \leq k\sqrt{n}\|A\|_\infty$,
  \end{itemize}
  where $\|A\|_\infty = \max \{ |A_{ij}|\ : \ A \in M_{n,k}(\mathbb{R})\}$.
  \qedwhite
\end{lemma}

%===============================================================================

\chapter{Ordinary differential equations}

Let $U \subset \mathbb{R}^n$ be open. A \textbf{vector field} or
\textbf{autonomous differential equation} is a continuous map $v : U \to
\mathbb{R}^n$ with no explicit time dependence. Here, $U$ is called the
\textbf{phase space} of $v$.

For $x \in U$, $\tau \in \mathbb{R}$, a continuous differential curve $\alpha :
(a,b) \to U$ is an \textbf{integral curve} of $v$ at $(x, \tau)$ if $\tau \in
(a,b)$, $\alpha(t) = x$ and $\alpha'(t) = v(\alpha(t))$. Note the integral
curves have tangent vectors which agree with $v$ at a given point.

More generally, for $U \in \mathbb{R}^n$, $I \subset \mathbb{R}$, a
\textbf{differential equation} is a continuous map $V : U\times I \to
\mathbb{R}^n$. A \textbf{solution} of $V$ at $x \in U$ and $\tau \in I$ is a
continuously differential curve $\alpha : I \to U$ with $\alpha'(t) =
V(\alpha(t), t)$ and $\alpha(t) = x$.

%-------------------------------------------------------------------------------

\section{Picard--Lindel\"of theorem}

This is an existence and uniqueness theorem for differential equations.

\begin{theorem}
  Let $U \subset \mathbb{R}^n$, $I \subset \mathbb{R}$ be open and $V : U\times
  I \to \mathbb{R}^n$ be a differential equation where, for all $x_1, x_2 \in
  U$, $t \in I$, there exists $L \geq 0$ such that\marginnote{Compare this with
  the \textbf{Lipschitz condition} where $\|v(x_1) - v(x_2)\| \leq L \|x_1 -
  x_2\|$, where $L$ is the \textbf{Lipschitz constant}.}
  \begin{equation*}
    \|v(x_1, t) - v(x_2, t)\| \leq L \|x_1 - x_2\|_2.
  \end{equation*}
  Given $(u, \tau) \in U \times I$, there exists $a,b>0$ with
  \begin{equation*}
    U_1 = \{x \in U\ :\ \|x - u\| < a\}, \quad I_1 = \{t \in I\ :\ |t - \tau| < b\}
  \end{equation*}
  such that the differential equation $v$ has an unique solution for all $x \in
  U_1$ and $\tau \in I_1$. Furthermore, the resulting $\alpha : U_1 \times I_1
  \to U$ given by $\alpha(x, t) = \alpha_{x}(t)$ is continuous.
\end{theorem}

\begin{proof}
  This one is quite long! The key idea is to construct a contraction mapping $A$
  and make use of the fixed point theorem to demonstrate existence and
  uniqueness. We are going to split this up into little bits.
  
  \begin{itemize}
    \item We first construct an integral curve $\alpha$ with
    $\partial\alpha/\partial t (x, t) = v(\alpha, t)$, $\alpha(x, \tau) = x$. By
    integrating,
    \begin{equation*}
      \alpha(x, t) = x + \int_\tau^t v(\alpha(x, s), s)\; \mathrm{d}s.
    \end{equation*}
    Define some operator $A$ such that
    \begin{equation*}
      A\beta(x, t) = x + \int_\tau^t v(\beta(x, s), s)\; \mathrm{d}s,
    \end{equation*}
    then we note that $A\alpha =\alpha$, and $\alpha$ is a fixed point of the
    operator $A$. We aim to show that $A$ is a contraction in a space satisfying
    the relevant properties.
    
    \item Let $a_1, b_1 > 0$ be such that
    \begin{equation*}
      D_1 = D(u; 2a_1) \subset U, \quad D_2 = D(\tau; b_1) \subset I.
    \end{equation*}
    By the Heine--Borel theorem\marginnote{Recall $D$ denotes \emph{closed}
    balls, while $B$ denote open balls.}, $D_1 \times D_2 \subset
    \mathbb{R}^{n+1}$ is compact, and so there exists some $K \geq 0$ such that,
    with respect to the Euclidean norm, $\|v(x, t)\| < K$ for all $(x, t) \in
    D_1 \times D_2$.
    
    Let $a, b > 0$ be such that
    \begin{equation*}
      0 < a < a_1, \qquad b < \min \left\{b_1, \frac{a}{K}, \frac{1}{L}\right\}.
    \end{equation*}
    Recall that $U_1 = B(u; a)$ and $I_1 = B(\tau; b)$, so let
    \begin{equation*}
      M = \{\beta\ :\ U_1 \times I_1 \to D \subset \mathbb{R}^n \}
    \end{equation*}
    where $\beta$ is continuous and $\beta(x, \tau) = x$ for all $x\in U_1$.
    This implies that
    \begin{equation*}
      M \subseteq \left( C_b(U_1 \times I_1) \right)^n,
    \end{equation*}
    and since $\left( C_b(U_1 \times I_1) \right)^n$ is a Banach space with the
    supremum norm, if $M$ is closed, then $M$ is complete.
    
    \item Suppose $(\beta_n) \in M$ where $\beta_n \to \beta$. For
    $(x, t) \in U_1 \times I_1$, $\|\beta(x, t) -
    \beta_n (x, t)\| \leq \|\beta - \beta_n\|$ so $\beta_n \to
    \beta$, but since $D_1$ is closed, $\beta \in D$ and obviously
    $\beta_n((x, \tau) \to \beta(x, \tau) =
    x$, so $M$ is closed and so is complete.
    
    \item If we now consider $A\beta$, then we have $A\beta(x,
    \tau) = x$ and that
    \begin{align*}
      \|A\beta(x, t) - u\| & \leq \|A((x, t) - x\|  - \| x - u\|\\
        &\leq \int_\tau^t \|v(\beta(x, s), s\|\; \mathrm{d}s + a\\
        &\leq K|t - \tau| + a\\
        &\leq Kb + a\\
        &< 2a < 2a_1 
    \end{align*}
    by Cauchy--Schwartz, definition of $U_1$, second bullet point, definition of
    $I_1$, and definition of $b$ and $a$ respectively. By definition of $D_1$,
    we have $A\beta(x, t) \in D_1$.
    
    \item Note then we have
    \begin{align*}
      \|A\beta(x, t) - A\beta(y, t') &\leq \|x - y\| + \left\|\int_\tau^t v(\beta(x, s), s) - v(\beta(y, s), s)\; \mathrm{d}s\right\|\\
        &\quad + \left\|\int_t^{t'} v(\beta(y, s), s)\; \mathrm{d}s\right\|\\
      &\leq \|x - y\| + L\int_\tau^t \left\|v(\beta(x, s), s) - v(\beta(y, s), s)\right\|\; \mathrm{d}s\\
        &\quad + K|t - t'|\\
      &\leq \|x - y\| + L \sup_{s\in[\tau, t]}\|\beta(x, s) - \beta(y, s)\| + K|t - t'|,
    \end{align*}
    by the Lipschitz conditions. All terms can be made arbitrarily small since
    $x$ can be made close to $y$, $t$ can be made close to $t'$, and since
    $[\tau, t]$ is compact, $\|\beta(x, s) - \beta(y, s)\|$ can be made
    arbitrarily small. So now $A\beta \in D_1$ is continuous, and therefore
    $A\beta \in M$, and $A : M \to M$ is a self mapping.
    
    \item Since $A$ is a self-mapping, for $\beta_{1,2} \in M$, we have
    \begin{align*}
      \|A\beta_1 - A\beta_2\| &\leq \int_\tau^t \|v(\beta_1(x, s), s) - v(\beta_2(x, s), s) \|\; \mathrm{d}s \\
        &\leq L \int_\tau^t \|\beta_1 - \beta_2\|\; \mathrm{d}s\\
        &= L |t - \tau| \|\beta_1 - \beta_2\|\\
        &\leq (Lb) \|\beta_1 - \beta_2\|
    \end{align*}
    by definition of $I_1$. Note that $Lb < 1$ by the definition of
    $b$\marginnote{$b < 1 / L$.}, and therefore $A$ is a contraction.
  \end{itemize}
  Since $A$ is a contraction and $M$ is complete, by contraction mapping there
  is one unique point in $M$ that is fixed under $A$. Clearly this is $\alpha$
  by definition of $\beta$ (see first bullet point), and hence $\alpha$ is the
  unique solution to the ODE satisfying the stated conditions. \qed
\end{proof}

Note that it doesn't matter if $\alpha : I_1 \to U$, since we can redefine $M$
and $A$ as $M_{x} = \{\beta\ :\ I_1 \to D\}$ with $\beta(t) = x$, and $A_{x} :
M_{x} \to M_{x}$. There will be an unique solution for fixed $x \in U_1$, where
the generation solution gives this solution.

%-------------------------------------------------------------------------------

\section{Differentiation in $\mathbb{R}^n$}

Let $U \subset \mathbb{R}^n$ be open. Recall that $f : U \to \mathbb{R}^n$ is differentiable at $x \in U$ with derivative
\begin{equation}
  Df(x) = \left(\frac{\partial f_i}{\partial x_j}\right) \in M_{p,n}(\mathbb{R})
\end{equation}
if near $x$ we can write
\begin{equation*}
  f(x + h) = f(x) + Df(x) \cdot h + R(h), \qquad \lim_{\|h\|\to 0} \frac{R(h)}{\|h\|} = 0.
\end{equation*}
If $f$ is differential for all $x \in U$, then $Df : U \to M_{p, n}(\mathbb{R})
= \mathbb{R}^{pn}$. If $D^i f$ is continuous then $f$ is said to be of
\textbf{$i$-class}, with $f \in C^i (U)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Mean value theorem}

\begin{theorem}
  Let $U \subset \mathbb{R}^n$ be open, $x \in U$, $h \in \mathbb{R}^n$ where $x
  + th \in U$ for all $t \in [0, 1]$ and $f \in C^1 : U \to \mathbb{R}^p$, then
  \begin{equation*}
    f(x + h) - f(x) = \int^1_0 Df(x + th)\cdot h\; \mathrm{d}t.
  \end{equation*}
\end{theorem}

\begin{proof}
  Let $f_i : U \to \mathbb{R}$ with $g_i(t) = f_i(x + th)$, so that $g : [0, 1]
  \to \mathbb{R}$. Then we have $g_i'(t) = Df_i(x + th) \cdot h$. By the
  fundamental theorem of calculus,
  \begin{align*}
    g_i(1) - g_i(0) &= \int_0^1 Df_i(x + th) \cdot h\; \mathrm{d}t \\
      &= f_i(x + th) - f_i(x).
  \end{align*}
  Since this is true per component, we have the result in higher dimensions. \qed
\end{proof}

\begin{corollary}
  Let $U \subset \mathbb{R}^n$ be open and convex\sidenote{So for all $x, y \in
  U$, $x t + (1-t)y \in U$ for $t\in[0, 1]$.}, and also that $f \in C^1 : U \to
  \mathbb{R}^n$. Assume that there exists some $C = \sup \{\|Df(x)\| \in
  \mathbb{R}\ :\ x \in U\}$, then $\|f(y) - f(x)\| \leq C\|y - x\|$.
\end{corollary}

\begin{proof}
  By the mean value theorem, we have
  \begin{align*}
    \|f(x + h) - f(x)\| &\leq \int_0^1 \|Df(x + h \cdot h\|\; \mathrm{d}t\\
      &\leq \int_0^1 \|Df(x + h)\| \cdot \|h\|\; \mathrm{d}t\\
      &\leq \int_0^1 C \cdot \|h\|\; \mathrm{d}t = C \cdot \|h\|.
  \end{align*}
  Since $h$ is arbitrary (up to us assuming convexity), letting $h = y - x$
  leads the result. \qed
\end{proof}

Note that for the above corollary, $U$ can always be reduced so that $C$ exists
locally. For the Picard--Lindel\"of theorem, we get $v \in C^1 : U \times I \to
\mathbb{R}$ implies the Lipschitz condition is satisfied locally.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Matrices}

Let $U \subset \mathbb{R}^n$ and $V \subset \mathbb{R}^p$ be open. A
$C^1$-function $f : U \to V$ is a \textbf{diffeomorphism} if there exists
$f^{-1} : V \to U$ where $f \circ f^{-1} = f^{-1} \circ f = \mbox{id}$ (the
identity map), and $f^{-1}$ is differential for all $x \in V$.

\begin{example}
  $f = x^3$ has $f^{-1} = x^{1/3}$, but since $f^{-1}$ is not differentiable at
  $x=0$, $x^3$ is not a diffeomorphism on $\mathbb{R}$.
\end{example}

By the chain rule, note that
\begin{equation*}
  D(f^{-1} \circ f) = \left(Df^{-1}(f)\right) Df = I_n, \quad D(f \circ f^{-1}) = \left(Df(f^{-1})\right) Df^{-1} = I_p.
\end{equation*}
If $y = f(x)$ then $Df^{-1}(y) = (Df(x))^{-1}$, then inverse matrix of $Df(x)$,
so $Df(x)$ is invertible and $p=n$ if $f$ is a diffeomorphism.

\begin{lemma}
  \begin{enumerate}
    \item $\mbox{GL}_n(\mathbb{R})$ is an open set\marginnote{This is the
    general linear group with real entries.}.
    \item $A \in M_{n,n}(\mathbb{R})$ with $\|A\| \leq 1$ implies that $I - A \in
    \mbox{GL}_n(\mathbb{R})$.
    \item $\mbox{inv} : \mbox{GL}_n(\mathbb{R}) \to \mbox{GL}_n(\mathbb{R})$
    with $A \mapsto A^{-1}$ is a smooth diffeomorphism.
  \end{enumerate}
\end{lemma}

\begin{proof}
  Recall that the determinant is defined as\marginnote{$S_n$ here is the group
  of symmetric permutations, and $\mbox{sig}(\sigma)$ is the signature of the
  permutation $\sigma$ ($+1$ if even and $-1$ if odd).}
  \begin{equation*}
    \mbox{det}\ A = |A| = \sum_{\mbox{sig} \in S_n} \mbox{sign}(\sigma) \prod_{i=1}^n a_{i, \sigma(i)}.
  \end{equation*}
  This is a polynomial in components of $A$, so it is a smooth function.
  
  \begin{enumerate}
    \item $\mbox{GL}_n(\mathbb{R}) = \mbox{det}^{-1}(\mathbb{R} - \{0\})$ so $A
    \in \mbox{GL}_n(\mathbb{R})$ implies that $|A| \neq 0$, which implies $|B|
    \neq 0$ for $B$ close to $A$, and thus $\mbox{GL}_n(\mathbb{R})$ is open.
    
    \item If $\|A\| \leq 1$, define $B_n = \prod_{i=0}^n A^i$ where $A^0 = I$.
    $\{B_n\}$ is a Cauchy sequence since
    \begin{equation*}
      \|B_n - B_m\| \leq \sum_{k = \min\{m,n\} + 1}^{\max\{m,n\}} \|A\|^k \leq \frac{\|A\|}{1 - \|A\|} \to 0
    \end{equation*}
    for sufficiently large $m,n$ with $\|A\| \leq 1$. So there exists $B =
    \lim_{n\to\infty} B_n$, and thus
    \begin{equation*}
      (I - A) B = (I - A) \lim_{n\to\infty} B_n.
    \end{equation*}
    $B_n$ continuous implies that
    \begin{equation*}
      (I - A)B = \lim_{n\to\infty} (I - A) B_n = \lim_{n\to\infty} I - A^{n+1} = I
    \end{equation*}
    since $\|A\| \leq 1$, so $B^{-1} = I - A \in \mbox{GL}_n(\mathbb{R})$.
    
    \item By Cramer's rule, for $A = (a_{ij})$, $A^{-1} = (b_{ij})$ with $b_{ij}
    = \mbox{det} A_{ij} / \mbox{det} A$, where $A_{ij}$ is the matrix obtained
    by replacing the $i^{\textnormal{th}}$ column with the standard
    $j^{\textnormal{th}}$ basis vector. So $(b_{ij})$ depends smoothly on
    $(a_{ij})$ since $\mbox{det}$ is a smooth map, and so $\mbox{inv}$ is
    smooth. Note additionally that $\mbox{inv}\circ\mbox{inv} = \mbox{id}$, so
    it is a bijection and hence a diffeomorphism.
  \end{enumerate}
  \qed
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Inverse function theorem}

Let $U \subset \mathbb{R}^n$ be open and $f \in C^k : U \to \mathbb{R}^n$. $f$
is \textbf{locally invertible} at $x \in U$ if there exists $U_1 \subset U$ such
that for $x \in U_1$, $V_1 \subset \mathbb{R}^n$ where $f(x) \in V_1$ is open
and $f: U_1 \to V_1$ is a diffeomorphism.

\begin{theorem}
  Let $U \subset \mathbb{R}^n$ be open and $f \in C^k : U \to \mathbb{R}^n$, $u
  \in U$. $f$ is locally invertible iff $Df(u)$ is invertible. Here the local
  inverse is of class $C^k$.
\end{theorem}

\begin{proof}
  This one is quite long!
  
  \begin{itemize}
    \item If $f$ is locally invertible at $u$, then it is a diffeomorphism, so
    clearly $Df(u)$ is invertible. However, this is for an isolated point, and
    we need to show that is also true on the appropriate neighbourhood.
    
    \item Assume that $u = 0 = f(u)$, i.e. a fixed point, and $Df(0) = I$.
    Define, for $y \in \mathbb{R}^n$,
    \begin{equation*}
      g_{y}(x) = y + x - f(x) \quad \Rightarrow \quad y - f(x) = g_{y} - x.
    \end{equation*}
    Note that $Dg_{y}(x) = I - Df(x)$ and does not depend on $y$. Also that
    $Dg_{y}(0) = I - I = 0$. 
    
    By continuity, we have $\|Dg_{y}(x) = \|Dg_{0}(x)\| \leq 1/2$
    for some $x$ near $0$. This implies that
    \begin{equation*}
      \|g_{y}(x_1 - g_{y}(x_2)\| \leq \frac{1}{2}\|x_1 - x_2\|
    \end{equation*}
    for $x_{1,2} \in D(0; r)$. Taking $x_2 = 0$, we also get
    \begin{equation*}
      \|g_{y}(x) - y\| \leq \frac{1}{2}\|x\|,
    \end{equation*}
    so we have
    \begin{equation*}
      \|g_{y}(x)\| \leq \frac{1}{2}\|x\| + \|y\|
    \end{equation*}
    for $y \in D(0; r/2)$ and $x \in D(0; r)$, and thus $\|g_{y}(x)\| \leq r$.
    Hence we have $g_{y}(x) : D(0; r) \to D(0; r)$, and $g_{y}(x)$ is by
    construction a contraction since $\|g_{y}(x_1 - g_{y}(x_2)\} \leq (1/2)\|x_1
    - x_2\|$.
  
    \item By contraction mapping theorem, for all $y \in D(0; r/2)$, there
    exists a unique $x \in D(0; r)$ with $y = f(x)$, so there exists an inverse
    function defined on $D(0; r/2)$.
    
    Define
    \begin{equation*}
      U_1 = \{x \in U\ :\ \|x\| < r, \|f(x)\| < r/2\}, \quad V_1 = f(U_1) = B(0; r/2).
    \end{equation*}
    By definition, both the domain and image are open sets. $f : U_1 \to V_1$ is
    a restricted bijection since it is a bijection on $D(0; r/2) \supset B(0;
    r/2)$. Given $x_{1,2} \in D(0; r)$, we have
    \begin{align*}
      \|x_1 - x_2\| &= \| g_{0}(x_1) + f(x_1) - g_{0}(x_2) + f(x_2)\| \\
        & \leq \|g_{0} - g_{0}(x_2)\| + \|f(x_1) - f(x_2)\| \\
        & \leq \frac{1}{2} \|x_1 - x_2\| + \|f(x_1) - f(x_2)\|,
    \end{align*}
    so that $\|x_1 - x_2\| \leq 2\|f(x_1) - f(x_2)\|$. For $x_2 = 0$, we have
    $\|x_1\| \leq 2\|f(x_1)\|$. Since $\|f(x_1)\| < r/2$ by construction, we
    have $\|x_1\| < r$, so indeed $V_1 = B(0; r/2)$.
    
    For $f^{-1} = \phi$, $\|x_1 - x_2\| \leq 2\|f(x_1) - f(x_2)\|$ implies that
    $\|\phi(y_1) - \phi(y_2)\| \leq 2\|x_1 - x_2\|$, so that $f^{-1}$ is
    Lipschitz continuous.
    
    \item Note that $Df(x)$ is invertible for all $x \in D(0; r)$, since we have
    $g_{0}(x) - x = f(x)$, so that $Df(x) = I - Dg_{0}(x)$, but $\|Dg_{0}(x)\|
    \leq 1/2$ from point 2 above, so $Df(x)$ is invertible for all $x \in
    D(0;r)$, and in particular for $x \in B(0; r) \subset D(0; r)$.
    
    \item Recall that if $f$ id differentiable, then $f(x_1) - f(x_2) =
    Df(x_1)(x_1 - x_2) + R(x_1 - x_2)$ with $R(h) / \|h\| \to 0$ as $\|h\| \to
    0$. Let $y_i = f(x_i)$. For $i=1,2$,
    \begin{equation*}
      y_1 - y_2 = Df(x_1)\left(\phi(y_1) - \phi(y_2)\right) + R\left(\phi(y_1) - \phi(y_2)\right),
    \end{equation*}
    so that
    \begin{align*}
      \left(Df(\phi(y_1))\right)^{-1}(y_1 - y_2) &= \left(\phi(y_1) - \phi(y_2)\right) \\
        &+\left(Df(\phi(y_1))\right)^{-1}R\left(\phi(y_1) - \phi(y_2)\right).
    \end{align*}
    
    We want to show that the remainder term tends to zero, which will show that
    $\phi = f^{-1}$ is differentiable. For that, note we have, by
    Cauchy--Schwartz and point 3 above,
    \begin{align*}
      \frac{\|\left(Df(\phi(y_1))\right)^{-1}R\left(\phi(y_1) - \phi(y_2)\right)\|}{\|y_1 - y_2\|} \leq  \frac{\|\left(Df(\phi(y_1))\right)^{-1}\|\cdot \|R\left(\phi(y_1) - \phi(y_2)\right)\|}{(1/2)\|\left(\phi(y_1) - \phi(y_2)\right)\|}.
    \end{align*}
    $\left(Df(\phi(y_1))\right)^{-1}$ is bounded since $f$ is differentiable.
    Further more, $f$ differentiable means $\|R\left(\phi(y_1) -
    \phi(y_2)\right)\| / \|\left(\phi(y_1) - \phi(y_2)\right)\| \to 0$ as
    $\|\left(\phi(y_1) - \phi(y_2)\right)\| \to 0$. Thus the desired remainder
    goes to zero since $y_1 - y_2 \to 0$ implies $\phi(y_1) - \phi(y_2) \to 0$,
    and $\phi = f^{-1}$ is differentiable.
    
    \item The derivative $D\phi(y) = (Df(\phi(y)))^{-1} = \mbox{inv} \circ Df
    \circ \phi)y$, so by construction, $D\phi = Df^{-1}$ is continuous. By chain
    rule, if $f\in C^k$, $D^{k-1}\phi$ is continuous, and thus $\phi = f^{-1}
    \in C^k$.
  \end{itemize}
  
   \qed
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Implicit function theorem}

\begin{theorem}
  Let $U\subset \mathbb{R}^n$, $V \subset \mathbb{R}^m$ be open and $f : U
  \times V \to \mathbb{R}^m$ be a $C^k$-function, with $k \geq 1$. Let $(u, v)
  \in U \times V$ such that the matrix $[\partial f_i / \partial x_j](u, v)$ is
  invertible with $\boldsymbol{c} = f(u, v)$. Then there is a $C^k$-function
  $\eta : U_1 \to V_1$ with $u \in U_1 \subset U$, $v \in V_1 \subset V$ where
  $\eta(u) = v$ and $f(x, \eta(x)) = \boldsymbol{c}$ for all $x \in N( (u, v);
  r)$. Further more, if $f(x, y) = \boldsymbol{c}$ for $(x, y) \in U_1 \times
  V_1$, then we have $y = \eta(x)$ in the respective sets.
\end{theorem}

\begin{proof}
  Define $\phi : U \times V \to \mathbb{R}^n \times \mathbb{R}^m$ where $(x, y)
  \mapsto (x, f(x, y))$. We have
  \begin{equation*}
    D\phi(u, v) = \begin{pmatrix}I & 0 \\ \partial f_i/\partial x_j (u, v) & \partial f_i / \partial x_j (u, v) \end{pmatrix},
  \end{equation*}
  so $\mbox{det} D\phi(u, v) \neq 0$, and so by the inverse function theorem,
  $\phi$ is locally a diffeomorphism.
  
  Since $\phi(x, y) = (x, f(x, y)$, we have $\phi^{-1}(A, \boldsymbol{b}) = (A,
  g(A, \boldsymbol{b})$. Setting $\eta(x) = g(x, \boldsymbol{c})$, then defining
  $\hat{p}_2$ as the projection operator for the second argument, we have
  \begin{align*}
    f(x, \eta(x)) &= f(x, g(x, c)) \\
      &= \hat{p}_2 \phi(x, g(x, c) \\
      &= \hat{p}_2 \phi \phi^{-1} (x, \boldsymbol{c}) \\
      &= \hat{p}_2(x, \boldsymbol{c}) = \boldsymbol{c}.
  \end{align*}
  So we have $f(x, y) = \boldsymbol{c}$ iff $y = \eta(x)$ for $(x, y) \in W$
  where $\phi$ is a diffeomorphism. This is achieved by choosing $u \in U_1
  \subset U$, $v \in V_1 \subset V$ so that $U_1 \times V_1 \subset W$, with
  $\eta(U_1) = V_1$. \qed
\end{proof}

The implicit function theorem gives a criterion of when we can solve $f(x, y) =
\boldsymbol{c}$ unique for $y$. In fact, if the linear equation $[Df(u, v)](x,
y) = 0$ is uniquely solvable, then $f(x, y) = \boldsymbol{c}$ is uniquely
solvable for $y$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Manifolds}

Let $M \subset \mathbb{R}^n$, $k \geq 0$, $\ell \geq 1$. $M$ is a
\textbf{$C^\ell$ $k$-dimensional manifold} if, for all $p \in M$, we also have
$p \in U \subset \mathbb{R}^n$ where there exists a $C^\ell$-diffeomorphism $h :
U \to U' \subset \mathbb{R}^k \times \mathbb{R}^{n-k}$ with $h(U \cap M) = U'
\cap (\mathbb{R}^k \times \{0\})$. Informally, a manifold is a structure where
every point of $M$ has a neighbourhood that resembles $\mathbb{R}^k$. $h$ here
is called a \textbf{chart}, which maps neighbourhoods of the manifold to
$\mathbb{R}^k$ (think \textbf{co-ordinate system} or segments of maps). A
collection of charts that spans the whole of $M$ is called an
\textbf{atlas}.\marginnote{Notice then in the previous proof, $\phi$ is a chart,
and $W \cap \{(x, y) \in \mathbb{R}^n\ : \ f(x, y) = \boldsymbol{c}\}$ is a
$k$-manifold.}

\begin{example}
  An open subset $U \subset \mathbb{R}$ is a $C^\infty$ $n$-manifold where the
  chart is $\mbox{id}: U \to U$.
  
  For a slightly less trivial example, consider the \textbf{unit $n$-sphere}
  $S^n = \{ x \in \mathbb{R}^{n+1}\ :\ \|x\| = 1\}$.\marginnote{Note that
  $2$-sphere would be the standard sphere, which is two-dimensional with zero
  volume.} With $f : \mathbb{R}^{n+1} \to \mathbb{R}$ with $x \mapsto \|x\|^2$,
  we have $S^n = f^{-1}(\{1\})$. For every $x \neq 0$, $Df(x) \neq 0$, so by
  implicit function theorem with respect to some co-ordinate system, there
  exists charts (it turns out an atlas for $S^n$ requires strictly more than 1
  chart). Since $f$ is a polynomial (e.g. standard Cartesian co-ordinates),
  $S^n$ is a $C^\infty$ $n$-manifold.
\end{example}

Let $f : U \subset \mathbb{R}^n \to \mathbb{R}^k$ be a $C^1$ function. A point
$x \in U$ is called a \textbf{critical point} if $\mbox{rank}(Df(x)) < k$, i.e.
the columns of the derivative matrix do not span $\mathbb{R}^k$, and $f(x)$ is
called a \textbf{critical value}. Otherwise $x$ is called a \textbf{regular
point}.

\begin{example}
  \begin{itemize}
    \item For $f: \mathbb{R}^n \to \mathbb{R}$ with $f(x) = \|x\|$, clearly $x =
    0$ is the only critical point, and 0 is the associated critical value.
    
    \item For $f:\mathbb{R}^n \to \mathbb{R}^k$, if $k > n$ then there are no
    regular points in $\mathbb{R}^n$ by definition.
    
    \item For $f:\mathbb{R}^3 \to \mathbb{R}^2$, is we have $f(x,y,z) = (\ex^z
    x, (y-1) \sin z)$, then
    \begin{equation*}
      Df(x,y,z) = \begin{pmatrix}
         \ex^z & 0 & \ex^z x\\
         0 & \sin z & (y-1)\cos z
      \end{pmatrix}.
    \end{equation*}
    If $\sin z \neq 0$ then all points are regular since $\ex^z \neq 0$. If
    $\sin z = 0$, then $\cos z = \pm 1$, and points with $y\neq 1$ are regular
    points. Otherwise, the critical points are $(x, 1, n\pi)$ with
    $n\in\mathbb{Z}$, and the critical values are $f(x, 1, n\pi) = (x\ex^{n\pi},
    0)$ (or just the whole $y=0$ line in $\mathbb{R}^2$).
  \end{itemize}
\end{example}

\begin{theorem}
  Let $f : U \subset \mathbb{R}^n \to \mathbb{R}^k$ be a $C^\ell$-map with $\ell
  \geq 1$, and $U$ is open. If $y \in \mathbb{R}^k$ is a regular value, then
  $f^{-1}(\{y\})$ is a $C^\ell$ $(n-k)$-manifold.
\end{theorem}

\begin{proof}
  Let $x \in f^{-1}(\{y\})$. Since $x$ is not a critical point, $Df(x)$ has rank
  $k$. After rearranging co-ordinates, we can assume that $(\partial f_i /
  \partial x_j)(x)$ is invertible, with $i = 1,\ldots k$ and $j = n-k+1$. The
  existence of the chart follows from the implicit function theorem, and so
  $f^{-1}(\{y\})$ is a $C^\ell$ $(n-k)$-manifold by definition. \qed
\end{proof}

Note that if $y \notin f(U)$ then $\phi = f^{-1}(\{y\})$ is still a
$(n-k)$-manifold.

\begin{example}
  \begin{itemize}
    \item For $f:\mathbb{R}^n \to \mathbb{R}$ with $x \mapsto \|x\|$, we have
    $S^{n-1} = f^{-1}(\{1\})$ following from previous example.
    
    \item For $f(x,y,z) = (\ex^z x, (y-1) \sin z)$, the inverse of the regular
    values $f^{-1}(\{(a,b)\ :\ b\neq 0\})$ is a $1$-manifold.
    
    \item For $f:\mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}^2$ with $(x, y)
    \mapsto (\|x\|, \|y\|)$, we have $f^{-1}(\{1, 1\}) = S^{n-1} \times
    S^{m-1}$.
  \end{itemize}
\end{example}

%===============================================================================

\chapter{Tangent spaces and vector fields}

Let $M \subset \mathbb{R}^n$ be a $C^\ell$ $k$-manifold with $\ell \geq 1$. The
\textbf{tangent vector} $v$ at $p \in M$ is an element in $\mathbb{R}^n$ of the
form $v = \gamma'(0)$ with $\gamma : (-\epsilon, \epsilon) \to M$ being a $C^1$
curve, and that $\gamma(0) = p$.

The set of all tangent vectors at point $p \in M$ is the \textbf{tangent space}
$T_p(M)$ at $p$.

\begin{proposition}
  Let $M \subset \mathbb{R}^n$ be a $C^\ell$ $k$-manifold, and $p \in M$. Then
  $T_p(M)$ is a $k$-vector space of $\mathbb{R}^n$. In fact, if $h : U \to U'
  \subset \mathbb{R}^k \times \mathbb{R}^{n-k}$ is a chart with $h(p) = 0$, then
  $T_p(M) \subseteq (Dh^{-1}(0))(\mathbb{R}^k \times \{0\})$.
\end{proposition}

\begin{proof}
  Let $h$ be a chart, $\gamma : (-\epsilon, \epsilon) \to M$ with
  $\gamma(0) = p \in U$. We can assume
  $\gamma : (-\epsilon, \epsilon) \to U \cap M$, so
  \begin{equation*}
    h \circ \boldsymbol{g} : (-\epsilon, \epsilon) \to \mathbb{R}^k \times \{0\},
  \end{equation*}
  which implies that
  \begin{equation*}
    \gamma = h^{-1} \circ h \circ \gamma,
  \end{equation*}
  so that
  \begin{equation*}
    v = \gamma'(0) = (Dh^{-1}(h\circ \gamma(0)))(h \circ \gamma)'(0) = Dh^{-1}(0) \cdot \boldsymbol{w},
  \end{equation*}
  and thus $T_p(M) \subseteq Dh^{-1}(0)(\mathbb{R}^k \times \{0\})$. On the
  other hand, let $\boldsymbol{\delta}(t) = t\boldsymbol{w}$, $\boldsymbol{w}
  \in \mathbb{R}^k$, and we get a curve in $M$ via $h^{-1} \circ
  \boldsymbol{\delta}$. By the chain rule,
  \begin{equation*}
    (h^{-1} \circ \boldsymbol{\delta})'(0) = Dh^{-1}(0) \cdot \boldsymbol{w},
  \end{equation*}
  which implies that $Dh^{-1}(0)(\mathbb{R}^k \times \{0\}) \subseteq T_p(M)$,
  and so $Dh^{-1}(0)(\mathbb{R}^k \times \{0\}) = T_p(M)$.
  
  The chart $h$ is a diffeomorphism so $h$ is injective, which means
  $\mbox{dim}(T_p(M)) = \mbox{dim}(\mathbb{R}^k) = k$, as required. \qed
\end{proof}

\begin{theorem}
  Let $g : U \subset \mathbb{R}^n \to \mathbb{R}^{n-k}$ be a $C^\ell$-function,
  $U$ is open, and $\boldsymbol{c} \in \mathbb{R}^{n-k}$ is a regular value.
  Then $M = g^{-1}(\{\boldsymbol{c}\})$ is a $k$-manifold and $T_p(M) =
  \mbox{ker}\{ Dg(p)\ : \ p\in M\}$. \qedwhite
\end{theorem}

Here the kernel is the one induced by the matrix representing the linear map.

\begin{example}
  Let $M = \{(x,y,z)\ : \ x^3 + y^3 + z^3 = 1\}$, and $g(x,y,z) = x^3 + y^3 +
  z^3$. If $p = (1, -1, 1)$, then $T_p(M) = \mbox{ker}(3(1)^2,
  3(-1)^2, 3(1)^2) = \mbox{ker}(3, 3, 3) = \{(x,y,z)\ : \ x + y + z = 0\}$. On
  the other hand, for $\boldsymbol{q} = (1,0,0)$, we have $T_q(M) =
  \mbox{ker}(3, 0, 0) = \{(x,y,z)\ : \ x = 0\}$.
\end{example}

Let $M \subset \mathbb{R}^n$ be a $C^1$ manifold, $u \subset \mathbb{R}^n$ open,
and $M \subset U$ with $f : U \to \mathbb{R}$ a $C^1$-function. The point $p \in
M$ is a \textbf{critical point} of $f|_M$ if for every $C^1$ curve $\gamma :
(-\epsilon, \epsilon) \to M$ with $\gamma(0) = p$, $(f \circ \gamma)'(0) = 0$,
i.e., the tangent vector is zero at the critical point $p$.

If $f|_M$ has a local extreme at $p \in M$ then $p$ is a critical point. By the
chain rule, $f|_M$ has a critical point exactly when $Df(p)|_{T_p(M)} = 0$.

%-------------------------------------------------------------------------------

\section{Method of Lagrange multipliers}

\begin{proposition}
  Let $U \subset \mathbb{R}^{n+m}$ be open, $g : U \to \mathbb{R}^n$ be a
  $C^\ell$-function with $\ell \geq 1$, and $0 \in \mathbb{R}^n$ be a regular
  value of $g$. For $f : U \to \mathbb{R}$ a $C^1$-function, $p \in M =
  g^{-1}(\{0\})$ is a critical point iff there exists some \textbf{Lagrange
  multipliers} $\lambda_1, \ldots \lambda_n \in \mathbb{R}$ with $D(f + \lambda_i
  g_i)(p) = 0$.\marginnote{Einstein summation convention implied.}
\end{proposition}

\begin{proof}
  Assume there exists the relevant Lagrange multipliers, then
  \begin{equation*}
    0 = D(f + \lambda_i g_i)(p) \quad \Leftrightarrow \quad Df(p) = -\lambda_i Dg_i(p).
  \end{equation*}
  Hence $Df(p)$ is a linear combination of row vectors of $Dg_i(p)$. Note that
  $Dg_i(p)|_{T_p(M)} = 0$ by the previous theorem, so $p$ is a critical point.
  
  On the other hand, note that $\mbox{rank}(Dg(p) = n)$ if $p$ is regular, so
  $Dg_i(p)$ are linear independent row vectors. Note also that $Df(p)$ is a
  linear map from $\mathbb{R}^{n+m}$ to $\mathbb{R}$, vanishing on $T_p(M)$
  which is $m$-dimensional and sits in the $n$-dimensional subvector space of
  the dual space $(R^{n+m})^*$ housing all of the $Dg_i(p)$. Since $Dg_i(p)$
  form a basis for this subspace, we must have constants where $Df(p) =
  -\lambda_i Dg_i(p)$. \qed
\end{proof}

The method of Lagrange multipliers gives a method of finding critical
points and extrema.\marginnote{So it is used a lot in optimisation
procedures.} Let $F : U \times \mathbb{R}^n \to \mathbb{R}$ with $(x, \lambda_1,
\ldots \lambda_n) \mapsto f(x) + \lambda_i g_i(x)$, the previous identity gives
\begin{equation}
  \frac{\partial F}{\partial x_i} = 0, \qquad \frac{\partial F}{\partial
  \lambda_j} = 0, \qquad i = 1, \ldots n+m, \quad j = 1,\ldots n.
\end{equation}
Solving the system gives finitely many critical points. Furthermore, if $M$ is
compact, then we can find extrema of $f$ via this method.

\begin{example}
  Find the maximum value of $f(x,y) = x+y$ on $M = \{(x,y)\ : \ x^4 + y^4 = 1\}$.
  
  Defining $g(x,y) = x^4 + y^4 - 1$, we have $g^{-1}(\{0\}) = M$ and is a
  manifold. We define
  \begin{equation*}
    F(x,y) = f + \lambda_i g_i = x + y + \lambda(x^4 + y^4 -1),
  \end{equation*}
  which results in
  \begin{align*}
    0 = \frac{\partial F}{\partial x} &= 1 + 4\lambda x^3,\\
    0 = \frac{\partial F}{\partial y} &= 1 + 4\lambda y^3,\\
    0 = \frac{\partial F}{\partial \lambda} &= x^4 + y^4 - 1.
  \end{align*}
  Since $(0,0) \notin M$, the first two equations give
  \begin{equation*}
    x = y = \left(-\frac{1}{4\lambda}\right)^{1/3},
  \end{equation*}
  so the constraint results in $\lambda = \pm 8^{1/4}/4$, and the critical
  points are $\pm(2^{-1/4}, 2^{-1/4})$. The maximum is thus
  \begin{equation*}
    f(2^{-1/4}, 2^{-1/4}) = \frac{2}{\sqrt{2}}.
  \end{equation*}
\end{example}

\begin{example}
  Find the extrema of $f(x,y,z) = 5x + y - 3z$ on the intersection of $x + y + z
  = 0$ with $S^2 = \{(x,y,z)\ : \ x^2 + y^2 + z^2 = 1\}$.
  
  Consider
  \begin{equation*}
    F(x,y,z,\lambda,\mu) = 5x + y - 3z + \lambda(x + y + z) + \mu(x^2 + y^2 + z^2 - 1).
  \end{equation*}
  It can be shown that $\lambda = -1$ from the first three equations. That
  results in $y\mu = 0$ in the second equation, and for a non-trivial
  constraint, we thus have $y=0$. This leads then in $x = -2\mu$, $z = 2/\mu$,
  resulting in $2x^2 = 1$, and thus the critical points are
  \begin{equation*}
    a = \left(\frac{1}{\sqrt{2}}, 0, -\frac{1}{\sqrt{2}}\right), \quad
    b = \left(-\frac{1}{\sqrt{2}}, 0, \frac{1}{\sqrt{2}}\right).
  \end{equation*}
  The extrema are then $f(a) = 8/\sqrt{2}$ and $f(b) = -8/\sqrt{2}$.
\end{example}

\begin{proposition}
  Let $A \subset \mathbb{R}^n$ be compact, $B \subset \mathbb{R}^n$ be closed,
  and both non-empty. Then there exists $a \in A$ and $b \in B$ where
  \begin{equation*}
    \|a - b\| \leq \|x - y\|
  \end{equation*}
  for all $x \in A$ and $y \in B$, and this can be any norm.
\end{proposition}

\begin{proof}
  Let $d = \inf \{\|x - y\|\ : \ x\in A, y \in B\}$. For all $n \in \mathbb{N}$,
  there exists some $a_n \in A$ and $b_n \in B$ such that
  \begin{equation*}
    \|a_n - b_n\| < d + \frac{1}{n}.
  \end{equation*}
  By passing to a sub-sequence, we can assume $a_n \to a$ since $A$ is compact.
  Then we see that
  \begin{equation*}
    \|b_n\| \leq \|b_n - a_n\| + \|a_n - a\| + \|a\| \leq d + 1 + \|a\|
  \end{equation*}
  for $n\gg1$. This implies that $B \cap D(0; d + 1 + \|a\|)$ is compact, so
  $b_n \to b$ as $n\to \infty$. Since $b \in B$, we have
  \begin{equation*}
    \|a - b\| \leq \|a - a_n\| + \|a_n - b_n\| + \|b_n - b\| < d + \epsilon
  \end{equation*}
  for some $\epsilon$. Since $d$ is the infimum, we must have $\|a - b\| \leq
  \|x + y\|$ for all $x \in A$ and $y \in B$. \qed
\end{proof}

\begin{example}
  Find $q \in M = \{x \in \mathbb{R}^3\ : \ 2x^ + y^2 + z = 1\}$ which has
  minimum distance to $p = (0, 0, -5)$.
  
  Now, $M = g^{-1}(\{0\})$ where $g = 2x^2 + y^2 + z - 1$, and since $0$ is a
  regular value, $M$ is closed (but not bounded). Let $f(x,y,z) = x^2 + y^2 +
  (z+5)^2 = \|x - p\|^2$ be the norm of choice, and minimising the norm gives us
  the desired solution. Consider
  \begin{equation*}
    F(x,y,z,\lambda) = x^2 + y^2 + (z+5)^2 + \lambda (2x^2 + y^2 + z - 1).
  \end{equation*}
  The usual manoeuver gives $x=0$ or $\lambda = -1/2$, which we consider
  separately.
  \begin{itemize}
    \item For $\lambda = -1/2$, we have $y=0$, $z=-19/4$, $x = \pm\sqrt{23/8}$,
    so $f(\pm\sqrt{23/8}, 0, -19/4) = 47/16 < 3$.
    
    \item For $x=0$, we have $y=0$ or $\lambda=-1$. The former case gives $z=1$
    and thus $f(0,0,1) = 36 > 3$. For $\lambda=-1$, we have $z=-9/2$ and thus
    $y=\pm\sqrt{11/2}$, which gives $f(0, \pm\sqrt{11/2}, -9/2) = 23/4 > 3$.
  \end{itemize}
  So $q = (\pm\sqrt{23/8}, 0, -19/4)$.
\end{example}

%-------------------------------------------------------------------------------

\section{Tangent spaces}

Let $M \subset \mathbb{R}^m$ and $N \subset \mathbb{R}^n$ be two $C^\ell$
manifolds, $\ell \geq 1$. Assume we have a continuous map $f : M \to N$ which
extends to a $C^1$ map $\overline{f} : U \to \mathbb{R}^n$, where $U \supset M$
is open. We define, for $p \in M$,
\begin{equation*}
  T_p(\overline{f}) : T_p (M) \to  T_{\overline{f}(p)}(N),
\end{equation*}
where for $\gamma : (-\epsilon, \epsilon) \to M$ a $C^1$ curve with $\gamma(0) =
p$ and $(\overline{f} \circ \gamma)(0) = \overline{f}(p)$, we have
\begin{equation*}
  T_p(\overline{f}) = (f \circ \gamma)'(0) \in T_{f(p)}(N).
\end{equation*}
By chain rule,
\begin{equation*}
  (\overline{f} \circ \gamma)' = D\overline{f}(\gamma(0))\cdot\gamma'(0) = D\overline{f}(p) \cdot \gamma'(0),
\end{equation*}
which implies that for $T_p(\overline{f}) : T_p(M) \to  T_{\overline{f}(p)}(N)$, we have
\begin{equation*}
  T_p(f(v)) = Df(p)\cdot v.
\end{equation*}
We observe that $v \in T_p(M)$ implies that $D\overline{f}(p)\cdot v \in
T_{\overline{f}(p)}(N)$, and $T_p(\overline{f})$ is a linear map between the two
tangent spaces.

A map $f: M\to N$ is called a \textbf{$C^\ell$ map} if $f$ extends to a $C^\ell$
map $\overline{f}: U \to \mathbb{R}^n$ as before. Here, if $T_p(f)$ is not
surjective, then $p \in M$ is a \textbf{critical point}, and $f(p)$ its
\textbf{critical value}.

\begin{theorem}
  Let $M \subset \mathbb{R}^m$ and $N \subset \mathbb{R}^n$ be two $C^\ell$
  manifolds, $\ell \geq 1$, and $f : M \to N$ which extends to a $C^\ell$ map.
  If $x \in N$ is a regular value, then $f^{-1}(\{x\})$ is a $C^\ell$ manifold
  of dimension $\mbox{dim}(M) - \mbox{dim}(N)$.
\end{theorem}

\begin{proof}
  Let $y \in f^{-1}(\{x\}) \subseteq M$, and we seek a chart around $y$. Let $s
  = \mbox{dim}(M)$ and $r = \mbox{dim}(N)$. We need
  \begin{equation*}
    \psi : U^r \subset \mathbb{R}^{s-r} \times \mathbb{R}^{m+r-s},
  \end{equation*}
  with
  \begin{equation*}
    \psi\left(f^{-1}(\{x\} \cap U)\right) = U' \cap \left(\mathbb{R}^{s-r} \times \{0\}\right).
  \end{equation*}
  Let $g : V \to \mathbb{R}^N \times \mathbb{R}^{n-r}$ be a chart around $x\in
  N$. Choose $U_y$ such that $y \in U_y$, $f(U_y) \subset V$, and a chart
  \begin{equation*}
    h : U_y \to U_y' \subset \mathbb{R}^s \times \mathbb{R}^{m-s}.
  \end{equation*}
  We have the following:
  
  \begin{tikzcd}
          \mathbb{R}^s \times \{0\} \arrow[r] & M \arrow[r, "f"] & N \arrow[r, "\hat{p}"] \arrow[dr, "g"] & \mathbb{R}^r \times \{0\}\\
          \mathbb{R}^s \times \mathbb{R}^{m-s} \arrow[ur, "h"] & & & \mathbb{R}^r \times \mathbb{R}^{n-r}
  \end{tikzcd}
  
  Let $\phi : \mathbb{R}^s \to \mathbb{R}^r$, which has full rank since
  \begin{itemize}
    \item a chart maps tangent plane to tangent plane
    \item $f$ is surjective by assumption since $x$ is a regular point
    \item a chart maps to tangent plane.
  \end{itemize}
  For $0 \in \mathbb{R}^s$ corresponding to $g\in M$ via $h$, $D\phi(0)$ has
  full rank. The same conclusion follows with $0 \in \mathbb{R}^r$ corresponding
  to $x\in N$ via $g$. Thus $\phi^{-1}(\{0\})$ is a manifold and corresponds to
  $f^{-1}(\{x\}) \cap U_y$ by
  \begin{equation*}
    h\left(\phi^{-1}(\{0\} \times \{0\})\right) = f^{-1}(\{x\}) \cap U_y,
  \end{equation*}
  so $\phi$ is a chart and $f^{-1}(\{x\})$ is a manifold. \qed
\end{proof}

%-------------------------------------------------------------------------------

\section{Vector fields}

Let $M \subset \mathbb{R}^n$ be a $C^\ell$ manifold with $\ell \geq 1$. A
continuous function $v : M \to \mathbb{R}^n$ is called a \textbf{vector field}
if $v(x) \in T_x(M)$ for all $x\in M$. It is called a \textbf{$C^\ell$-vector
field} if there is an open set $U \subset \mathbb{R}^n$ containing $M$ such that
$v$ extends to a $C^\ell$ function $\overline{v} : U \to \mathbb{R}^n$.

\begin{example}
  For $S^{n-1} = \{x \in \mathbb{R}^n\ :\ \|x\|^2 = 1\}$. Let $g(x) = \|x\|^2$,
  then $S^{n-1} = g^{-1}(\{1\})$. By theorem,
  \begin{align*}
    T_p(S^{n-1}) = \mbox{ker}Dg(p) = \mbox{ker}(2p) &= \{x \in \mathbb{R}^n\ :\ 2x_i p_i = 0\}\\
      &= \{x \in \mathbb{R}^n\ :\ (x, p) = 0\}.
  \end{align*}
  So for a vector field $v(x)$ on $S^{n-1}$, we need $(x, v(x)) = 0$ for all $x
  \in S^{n-1}$. For $n = 2m$, let $v : \mathbb{R}^{2m} \to \mathbb{R}^{2m}$,
  with
  \begin{equation*}
    (x_1, \ldots, x_{2m}) \mapsto (-x_2 x_1, -x_3 x_2, \ldots, -x_{2m} x_{2m-1}).
  \end{equation*}
  Here we have $(x, v(x)) = 0$ for all $x \in \mathbb{R}^{2m}$, so $v$ restricts
  to a vector field on $S^{2m-1}$, is $C^\infty$, and $v(x) \neq 0$ for all $x
  \in S^{2m-1}$. 
  
  $v$ is called a \textbf{non-vanishing vector field} in this case. Note that
  there are no non-vanishing vector fields on $S^{2m}$.\marginnote{This is
  related to the \textbf{hairy ball theorem}.}
\end{example}

\begin{example}
  For $0 < \epsilon < 1$, define
  \begin{equation*}
    \phi : (1-\epsilon, 1+\epsilon) \times \mathbb{R}^2 \to \mathbb{R}^3; \quad \Phi(r, \phi, \theta) = \begin{pmatrix}(2+r\cos\phi) \cos\theta \\ (2+r\cos\phi)\sin\theta \\ r\sin\phi \end{pmatrix},
  \end{equation*}
  where $\phi$ and $\theta$ are both full angles from $0$ to $2\pi$. The
  \textbf{$2$-torus} is then
  \begin{equation*}
    T^2 = \{x \in \mathbb{R}^3\ :\ (x,y,z) = \Phi(1, \phi, \theta)\}.
  \end{equation*}
  If we restrict $\Phi$ to small angles we get charts, and so we get tangent
  plans and vector fields. Note that the $2$-torus does have non-vanishing
  vector fields, compared to the $2$-sphere.
\end{example}

Let $U, V \subset \mathbb{R}^n$ be open sets, $h : U \times V$ be a $C^\infty$
diffeomorphism, and $v : U \to \mathbb{R}^n$ be a vector field. We define the
vector field on $v$ by
\begin{equation*}
  h * v : V \to \mathbb{R}^n, \quad h * v(x) = Dh\left(h^{-1}(x)\right)\cdot v(h^{-1}(x)).
\end{equation*}

\begin{lemma}
  If $M$ is a $C^\infty$ manifold and $v$ a $C^\ell$ vector field, with $\ell
  \geq 1$. For all $p \in M$, there exists open $I \subset \mathbb{R}$ with $0
  \in I$, and an integral curve $\gamma : I \to M$ such that $\gamma(0) = p$,
  $\gamma'(t) = v(\gamma(t))$ for all $t \in I$.
  \qedwhite
\end{lemma}

\begin{lemma}
  As above, for $i=1,2$, let $\gamma_i : I_i \to M$ be integral curves of $v$
  with $\gamma_1(0) = p = \gamma_2(0)$, $I_i$ open, and $0 \in I_i$. Then
  $\gamma_1(t) = \gamma_2(t)$ for all $t \in I_1 \cap I_2$.
\end{lemma}

\begin{proof}
  Uniqueness follows from the Picard--Lindel\"of theorem. \qed
\end{proof}

Note that the integral curve can now be extended to an integral curve of $I_1
\cup I_2$, and we get a maximal curve through a point $p$ this way.

\begin{proposition}
  Let $M$ be a compact $C^\infty$ manifold and $v$ and $C^\ell$ vector field
  with $\ell \geq 1$. For all $p \in M$, there exists $\gamma : \mathbb{R} \to
  M$ with $\gamma(0) = p$.
\end{proposition}

\begin{proof}
  Let $\gamma : I \to M$ be the maximal integral curve, and assume $I \cap [0,
  \infty)$ is bounded. Then these exists $T = \sup\{I \cap [0, \infty)\}$.
  Choose a sequence $(t_n) \in I$ with $t_n \to T$, then $\gamma(t_n)$ is a
  sequence in $M$. Since $M$ is compact, we can assume $\gamma(t_n) \to x \in
  M$.
  
  Let $\beta : (T-\epsilon, T+\epsilon) \to M$ be an integral curve with
  $\beta(T) = x$. Since $t_n \to T$ for large $n$, and $t_n \in (T-\epsilon,
  T+\epsilon)$, we should have $\gamma(t_n) = \beta(t_n)$ by uniqueness, and so
  $\gamma$ can be extended beyond $T$. However, this is a contradiction since
  $\gamma$ was assumed to be maximal, so $I$ is not bounded, and thus $\gamma$
  can be extended to $\mathbb{R}$. \qed
\end{proof}

For $v$ a $C^\ell$ vector field ($\ell \geq 1$) on a compact manifold $M$, the
\textbf{flow} $\Phi$ is defined as
\begin{equation}
  \Phi : M \times \mathbb{R} \to M, \qquad (x, t) \mapsto \gamma_x(t)
\end{equation}
where $\gamma_x$ is the integral curve with $\gamma_x(0) = x$.

\begin{theorem}
  Let $M$ be a compact $C^\infty$ manifold and $v$ a $C^\ell$ vector field,
  $\ell \geq 1$. Then the flow $\Phi$ is continuous and
  \begin{enumerate}
    \item $\Phi(x, 0) = x$ for all $x \in M$,
    \item $\Phi(\Phi(x, t), x) = \Phi(x, t+s)$ for all $x\in M$, $t,s \in \mathbb{R}$.
  \end{enumerate}
\end{theorem}

\begin{proof}
  Continuity holds and follows from Picard--Lindel\"of, and $\Phi(x,0) = x$
  follows from definition of the flow map. Let $y = \Phi(x, t)$, so $\gamma_x(t)
  = y$. Define $\gamma(u) = \gamma_x(u+t)$, which is an integral curve with
  $\gamma(0) = y$. By uniqueness, $\gamma = \gamma_y$, and so
  \begin{equation*}
    \Phi(\Phi(x, t), s) = \gamma_y(s) = \gamma(s) = \gamma_x(s+t) = \Phi(x, t+s).
  \end{equation*}
  \qed
\end{proof}

Note that if we write $x\cdot t = \Phi(x,t)$, then $x\cdot 0 =x$, and $(x\cdot
t)\cdot s = x\cdot (t+s)$, so the abelian group $\mathbb{R}$ acts on the set
$M$. Since $\Phi$ is continuous we have a topological action. Every $C^1$ vector
field $v$ on a compact manifold $M$ gives rise to an $\mathbb{R}$-action on $M$.

Note also that $v$ is of $C^\ell$ class implies that $\Phi$ is of $C^\ell$
class.

%===============================================================================

\chapter{Differential forms on $\mathbb{R}^n$}

In lower dimensions, from the standard fundamental theorem of calculus, Stokes'
theorem and divergence theorem, we see we have identities of the form
\begin{equation}
  \int_M \mathrm{d}\omega = \int_{\partial M} \omega,
\end{equation}
where $M$ is some (oriented) manifold, and $\omega$ is some function / vector
field. This is in fact true in higher dimensions, and the result is the
\textbf{generalised Stokes' theorem}. It will be seen $\omega$ is a
\textbf{differential $k$-form}, and $M$ are the \textbf{oriented
$\ell$-manifolds} in $\mathbb{R}^n$ with boundary $\partial M$. To get to the
general result, we go through some machinery first in $\mathbb{R}^n$, before
proceeding to general (oriented) manifolds.

%-------------------------------------------------------------------------------

\section{Riemann integrals}

For $f: [a,b] \to \mathbb{R}$, recall that for a partition $Z = \{t_0, t_1,
\ldots, t_n\}$, the \textbf{upper/lower Riemann sums} are defined as
\begin{equation}
  \mathcal{U}(f, Z) = \sum_{i=0}^{n-1} M_i(f)(t_{i+1}-t_i), \qquad \mathcal{L}(f, Z) = \sum_{i=0}^{n-1} m_i(f)(t_{i+1}-t_i),
\end{equation}
where for $x \in [t_{i-1}, t_i]$,
\begin{equation*}
  M_i(f) = \sup f(x), \quad m_i(f) = \inf f(x).
\end{equation*}
If $Z'$ is a \textbf{refinement} of $Z$ (i.e. $Z' \supset Z$, where $Z'$ is a
partition), then
\begin{equation*}
  \mathcal{L}(f, Z) \leq \mathcal{L}(f, Z') \leq \mathcal{U}(f, Z') \leq \mathcal{U}(f, Z).
\end{equation*}
For two partitions, the \textbf{common refinement} is $Z'' = Z' \cup Z$, which
implies that
\begin{equation*}
  \mathcal{L}(f, Z) \leq \mathcal{L}(f, Z'') \leq \mathcal{U}(f, Z'') \leq \mathcal{U}(f, Z').
\end{equation*}
The \textbf{upper Riemann integral} is then defined as
\begin{equation}
  \int_{[a,b]}^u f\; \mathrm{d}x = \inf \{\mathcal{U}(f, Z)\ :\ Z\ \textnormal{a partition of } [a,b]\},
\end{equation}
while the \textbf{lower Riemann integral} is
\begin{equation}
  \int_{[a,b]}^l f\; \mathrm{d}x = \inf \{\mathcal{L}(f, Z)\ :\ Z\ \textnormal{a partition of } [a,b]\}.
\end{equation}
For bounded $f$, we should have
\begin{equation*}
  \int_{[a,b]}^l f\; \mathrm{d}x \leq \int_{[a,b]}^u f\; \mathrm{d}x \leq \infty.
\end{equation*}
If the two sums coincide as $|t_{i-1} - t_i|\to 0$, then $f$ is \textbf{Riemann
integrable}.

In $\mathbb{R}^n$, to generalise, $f$ defined analogously if each individual
component of $f$ is Riemann integrable.

\begin{lemma}
  Let $f : [a,b] \to \mathbb{R}^n$ be integrable. Then $\|f\|$ is also integrable and
  \begin{equation*}
    \left\| \int_{[a,b]} f\; \mathrm{d}x \right\| \leq \int_{[a,b]} \|f\|\; \mathrm{d}x.
  \end{equation*}
\end{lemma}

\begin{proof}
  $\|f\|$ is clear integrable. We see that for all $\epsilon>0$, there exists a
  common partition $Z$ such that
  \begin{equation*}
    \mathcal{U}(f_i, Z) - \mathcal{L}(f_i, Z) \leq \epsilon, \quad \mathcal{U}(\|f\|, Z) - \mathcal{L}(\|f\|, Z) \leq \epsilon
  \end{equation*}
  for all components $f_i$ of $f$. For any partition $Z = \{x_0, \ldots, x_n\}$
  and any choice $\xi_i$
  \begin{equation*}
    a = x_0 \leq \xi_0 \leq x_1 \leq \xi_1 \leq \ldots \leq x_{n-1} \leq \xi_{n-1} \leq x_n = b,
  \end{equation*}
  we have
  \begin{equation*}
    \left\|\sum_{i=0}^{n-1} f(\xi_i)(x_{i+1} - x_i) \right\| \leq \sum_{i=0}^{n-1} \|f(\xi_i)\|(x_{i+1} - x_i)
  \end{equation*}
  by the triangle inequality. For such a partition $Z$, we have both
  \begin{align*}
    \left| \int_a^b f_i\; \mathrm{d}x - \sum_{k=0}^{n-1} f_i(\xi_k)(x_{k+1} - x_k)\right| &\leq \epsilon,\\
    \left| \int_a^b \|f\|\; \mathrm{d}x - \sum_{k=0}^{n-1} \|f(\xi_k)\|(x_{k+1} - x_k)\right| &\leq \epsilon,
  \end{align*}
  which implies that, considering each component,
  \begin{equation*}
    \left\| \int_a^b f\; \mathrm{d}x - \sum_{k=0}^{n-1} f(\xi_k)(x_{k+1} - x_k) \right\| \leq \sqrt{n\epsilon^2} = \sqrt{n} \epsilon.
  \end{equation*}
  Then,
  \begin{align*}
    \left\|\int_{[a,b]} f\; \mathrm{d}x \right\| &\leq \left\|\sum_{k=0}^{n-1} f(\xi_k)(x_{k+1} - x_k) \right\| + \sqrt{n} \epsilon \\
      &\leq \sum_{k=0}^{n-1}\left\| f(\xi_k)(x_{k+1} - x_k) \right\| + \sqrt{n} \epsilon\\
      &\leq \int_a^b \|f\|\; \mathrm{d}x + \epsilon + \sqrt{n}\epsilon.
  \end{align*}
  Since $\epsilon$ was arbitrary, we have the result as required. \qed
\end{proof}

%-------------------------------------------------------------------------------

\section{Differential 1-forms and line integrals}

Let $V$ be a real vector space with norm $\|\cdot\|$, and $c:[a,b] \to V$ be
continuous. The \textbf{length} of $c$ is defined as
\begin{equation*}
  L(c) = \sup \left\{\sum_i^{n-1} \|c(t_{i+1} - c(t_i)\|\ :\ \forall\ n\in N, t_i \ in Z\right\}.
\end{equation*}
The curve $c$ is \textbf{rectifiable} if $L(c) < \infty$.

Note that the length of a curve is (and should be) independent of its
parameterisation.

\begin{proposition}
  For $c: [a,b] \to^n$ of class $C^1$, $c$ is rectifiable, and $L(c) = \int_a^b
  \|c'(t)\|\; \mathrm{d}t$.
\end{proposition}

\begin{proof}
  Note that
  \begin{align*}
    \sum_i \| c(t_{i+1} - c(t_i)\| & = \sum_i \left\| \int_{[t_i, t_{i+1}]} c'(t)\; \mathrm{d}t\right\| \\
      & \leq \sum_i \int_{[t_i, t_{i+1}]} \|c'(t)\|\; \mathrm{d}t\\
      &= \int_a^b \|c'(t)\|\; \mathrm{d}t < \infty
  \end{align*}
  since $c \in C^1[a,b]$, so $L(c) < \infty$ and $c$ is rectifiable.
  
  Let $f(t) = L\left(c|_{[a,t]}\right)$ for $a \leq t_0 < t \leq b$. Then
  \begin{align*}
    \left|\frac{c(t) - c(t_0)}{t - t_0} \right| \leq \frac{L\left(c|_{[t_0,t]}\right)}{t - t_0}  &= \frac{f(t) - f(t_0)}{t - t_0} \\
      &\leq \frac{1}{t - t_0} \int_{[t_0, t]} \|c'(s)\|\; \mathrm{d}s = \|c'(t_1)\|
  \end{align*}
  for $t_1 \in [t_0, t]$ by the mean value theorem. So as $t_0, t_1 \to t$,
  \begin{equation*}
    \|c'(t)\| \leq f'(t) \leq \|c'(t)\|,
  \end{equation*}
  and so $f'(t)$ exists and $f'(t) = \|c'(t)\|$. Thus
  \begin{equation*}
    L(c) = f(b) - f(a) = \int_a^b f'(t)\; \mathrm{d}t = \int_a^b \|c'(t)\|\; \mathrm{d}t < \infty
  \end{equation*}
  as required. \qed
\end{proof}

\begin{example}
  For the helix, we have $c(t) = (at, r\cos t, r\sin t)$, so $\|c'(t)\| =
  \sqrt{r^2 + a^2}$, and
  \begin{equation*}
    L(c)|_{[0, 2\pi]} = \int_0^{2\pi} \sqrt{r^2 + a^2}\; \mathrm{d}t = 2\pi \sqrt{r^2 + a^2}.
  \end{equation*}
\end{example}

Recall the differential $Df(x) : \mathbb{R}^n \to \mathbb{R}$ is a linear map.
Denote this now has $\mathrm{d}f_x : \mathbb{R}^n \to \mathbb{R}$, and the real
vector space of all linear maps $\phi : \mathbb{R}^n \to \mathbb{R}$ to be
$\mathcal{L}(\mathbb{R}^n, \mathbb{R})$. Since $\phi \in
\mathcal{L}(\mathbb{R}^n, \mathbb{R})$ is linear, we only investigate the action
of $\phi$ on the basis $\{e_i\}$. We see that
\begin{equation*}
  \mathrm{d}f_x (e_i) = \frac{\partial f}{\partial x_i}(x),
\end{equation*}
so\marginnote{Einstein summation.}
\begin{equation*}
  \mathrm{d}f_x (v) = \frac{\partial f}{\partial x_i} v_i = \langle \nabla f, v\rangle
\end{equation*}
for $\langle\cdot,\cdot\rangle$ the inner product on some vector space $V$
housing $v$. We see $\partial f / \partial x_i$ are smooth coefficient
functions, and that since $f: U \to \mathbb{R}^n$ is smooth, $\mathrm{d}f: U \to
\mathcal{L}(\mathbb{R}^n, \mathbb{R})$.

Let $U \subset \mathbb{R}^n$ be open and $\omega : U \to
\mathcal{L}(\mathbb{R}^n, \mathbb{R})$, then there are functions $f_1, \ldots
f_n : U \to \mathbb{R}^n$ where
\begin{equation}
  \omega_x(v) = f_i(x) v_i
\end{equation}
for all $x \in U$, $v = v_i e_i$. The coefficient functions $f_i$ are calculated
via
\begin{equation}
  f_i(x) = \omega_x(e_i).
\end{equation}
We call $\omega$ a \textbf{differential 1-form} on $U$ if $f_i : U \to
\mathbb{R}$ are of class $C^\infty$ for all $i$. The set of all 1-forms is
denoted by $\Omega^1(U)$, which has the structure of a real vector space. One
can canonically multiply a 1-form $\omega \in \Omega^1(U)$ with a smooth
function $f\in C^\infty(U)$ by performing
\begin{equation*}
  (f\omega)_x (v) = f(x) \omega_x(v).
\end{equation*}

\begin{lemma}
  Let $\omega$ be a 1-form and $U \subset \mathbb{R}^N$ be open. Then there
  exists a smooth vector field $X_\omega : U \to \mathbb{R}^n$ where
  \begin{equation*}
    \omega_x (v) = \langle X_\omega (x), v\rangle.
  \end{equation*}
\end{lemma}

\begin{proof}
  Since $F_\omega = f_i e_i$, $\langle F_\omega(x), v\rangle = f_i(x) \langle
  e_i, v\rangle = f_i(x) v_i = \omega_x(v)$. \qed
\end{proof}

\begin{lemma}
  Let $\omega \in \Omega^1(U)$, $x_i : U \to \mathbb{R}$, $x_i(p_1, \ldots, p_n)
  = p_i$. Then $\omega = f_i\ \mathrm{d}x_i$ and $f_i(x) = \omega_x (e_i)$.
\end{lemma}

\begin{proof}
  Since
  \begin{equation*}
    \mathrm{d}x_i(x)(v) = \frac{\partial x_i}{\partial x_j}(x)v_j = v_i,
  \end{equation*}
  we have
  \begin{equation*}
    \omega_x(v) = f_i(x) v_i = f_i(x)\; \mathrm{d}x_i(x)(v),
  \end{equation*}
  and since $v$ was arbitrary, $\omega_x = f_i(x)\; \mathrm{d}x_i$. \qed
\end{proof}

\begin{example}
  Suppose $\omega \in \Omega^1(\mathbb{R}^2)$ and $\omega = 3xy\; \mathrm{d}x +
  y^3\; \mathrm{d}y$, and we take $p = (7,3)$. Then since
  \begin{equation*}
    \omega_p(e_1) = 3\cdot p_1\cdot p_2\; \mathrm{d}x(e_1) + p_2^3\; \mathrm{d}y(e_1) = 3\cdot7\cdot1 + 27\cdot 0 = 63,
  \end{equation*}
  while $\omega_p(e_2) = 27$ by a similar argument. So $\omega_p((1, -2)) = 63 -
  2\cdot27=9$ for example.
\end{example}

A differential 1-form $\omega$ is \textbf{exact} if there exists some $f \in
C^\infty(U)$ where
\marginnote{A 1-form eats a vector and spits out a number. Sometimes it can be regarded as a functional (eats a function and spits out a number). Eactness is like a function (0-form) having a primitive when we are talking about integration.}
\begin{equation}
  \omega = \mathrm{d}f.
\end{equation}

For $U \subset \mathbb{R}^n$ open and $c:[a,b] \to U$ be smooth and $\omega \in
\Omega^1(U)$. The \textbf{line integral} of $\omega$ along $c$ is
\begin{equation}
  \int_c \omega = \int_a^b \omega_{c(t)} \left(c'(t)\right)\; \mathrm{d}t.
\end{equation}
If $c$ is piecewise smooth, we can still define the integral.

For $c:[a,b] \to \mathbb{R}^n$ a smooth curve and $\phi : [\alpha,\beta] \to
[a,b]$ be a smooth bijective map, then $\tilde{c} = c\circ \phi : [\alpha,
\beta] \to \mathbb{R}^n$ is a \textbf{orientation preserving reparameterisation}
if $\phi' > 0$, otherwise it is orientation reversing.

\begin{proposition}
  For $\omega \in \Omega^1(U)$, $c:[a,b] \to U$, $\tilde{c} = c\circ \phi :
  [\alpha, \beta] \to U$ orientation preserving,\sidenote{If orientation
  reversing, then there would be an extra minus sign.}
  \begin{equation*}
    \int_c \omega = \int_{\tilde{c}} \omega.
  \end{equation*}
\end{proposition}

\begin{proof}
  \begin{align*}
    \int_{\tilde{c}} \omega = \int_\alpha^\beta \omega_{\tilde c}(\tilde{c}')\; \mathrm{d}t
      &= \int_\alpha^\beta \omega_{c\circ\phi} \left((c\circ\phi)'\right)\; \mathrm{d}t\\
      &=\int_\alpha^\beta \omega_{c\circ\phi} \left((c'\circ\phi)\right)\phi'\; \mathrm{d}t\\
      &=\int_a^b \omega_{c} \left(c'\right)\; \mathrm{d}t = \int_c \omega.
  \end{align*}
  \qed
\end{proof}

\begin{lemma}
  For $f \in C^\infty(U)$, $c:[a,b] \to U$, then
  \begin{equation*}
    \int_c \mathrm{d}f = f(c(b)) - f(c(a)).
  \end{equation*}
\end{lemma}

\begin{proof}
  \begin{align*}
    \int_c \mathrm{d}f = \int_a^b \left[Df(c(t))\right](c'(t))\; \mathrm{d}t = \int_a^b (f\circ c)'(t)\; \mathrm{d}t = f(c(b)) - f(c(a)).
  \end{align*}
  \qed
\end{proof}

\begin{proposition}
  Let $U\subset\mathbb{R}^n$ be open and path connected, then the following are
  equilvalent:
  \begin{enumerate}
    \item $\omega \in \Omega^1(U)$ is exact,
    \item $\int_c \omega$ depends only on the end points (i.e. path
    independence),
    \item $\oint_c \omega = 0$.
  \end{enumerate}
\end{proposition}

\begin{proof}
  \begin{itemize}
    \item 1) implies 2) by previous lemma.
    \item 2) implies 3). Consider $c$ with $c(a) = c(b) = p \in U$, and $c_p(t)
    = p$ for all $t$. Then since $c_p'(t) = 0$, $\int_{c_p} \omega = 0$ and so
    $\oint_c \omega = 0$ since we assumed path independence.
    \item 3) implies 2). For $c = c_1 \cup (-c_2)$,
    \begin{equation*}
      0 = \oint_c \omega = \int_{c_1} \omega + \int_{-c_2} \omega = \int_{c_1} \omega - \int_{c_2} \omega,
    \end{equation*}
    which implies path independence.
    \item 2) implies 1). Choosing $p \in U$, $f: U \to \mathbb{R}$ via $f(q) =
    \int_c \omega$, $c(0) = p$, $c(1) = q$, then $f$ is well-defined by 2).
    Choose $h \in \mathbb{R}^n$ where $h + q \in U$, let
    \begin{equation*}
      \gamma : [0, 1] \to I, \quad \gamma(t) = q + th.
    \end{equation*}
    Then
    \begin{equation*}
      f(q+th) - f(q) = \int_\gamma \omega = \int_0^1 \omega_\gamma(\gamma')\; \mathrm{d}t \int_0^1 \omega_{q+th}(h)\; \mathrm{d}t.
    \end{equation*}
    Now introduce vector field $X_\omega$, an by lemma,
    \begin{align*}
      f(q+th) - f(q) - \omega_q(h) &= \int_0^1 \left(\omega_{q+th}(h) - \omega_q(h)\right)\; \mathrm{d}t\\
        & =\int_0^1 \langle X_\omega (q+th) - X_\omega (q), h\rangle \; \mathrm{d}t\\
        & \leq \int_0^1 \left\| X_\omega (q+th) - X_\omega (q)\right\|\; \mathrm{d}t \cdot \|h\|.
    \end{align*}
    The right hand side has $R(h) / \|h\| \to 0$ as $h\to 0$ since $X_\omega$ is
    continuous, so $f$ is differentiable, and
    \begin{equation*}
      \omega_q(h) = Df(q)(h) = \mathrm{d}f_q (h),
    \end{equation*}
    and since $q$ and $h$ are arbitrary, $\omega = \mathrm{d}f$.
  \end{itemize}
  \qed
\end{proof}

\begin{proposition}
  If $\omega \in \Omega^1(U)$ is exact and $\omega = f_i\; \mathrm{d}x_i$, then
  \begin{equation*}
    \frac{\partial f_i}{\partial x_j} = \frac{\partial f_j}{\partial x_i}
  \end{equation*}
  for all $i$ and $j$.
\end{proposition}

\begin{proof}
  Since
  \begin{equation*}
    \omega = \mathrm{d}f = \frac{\partial f}{\partial x_i}\; \mathrm{d}x_i,
  \end{equation*}
  we have $f_i = \partial f/ \partial x_i$, so then since $f$ is differentiable,
  \begin{equation*}
    \frac{\partial f_i}{\partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i} = \frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f_j}{\partial x_i}.
  \end{equation*}
  \qed
\end{proof}

$\omega \in \Omega^1(U)$ is \textbf{closed} if for $\omega = f_i\; \mathrm{d}x_i$, $\partial f_i / \partial x_j = \partial f_j / \partial x_i$. We see that exactness implies closed, but the converse is generally not true (but see Poincar\'e's lemma below). Note that, in $\mathbb{R}^3$, $\omega \in \Omega^1(U)$ is closed if $\nabla \times X_\omega = 0$.

A subset $U\subset \mathbb{R}^3$ is \textbf{star-like} if there exists $\boldsymbol{p} \in  U$ such that for all $\boldsymbol{q} \in U$, the straight line segment joining $\boldsymbol{p}$ and $\boldsymbol{q}$ is entirely in $U$. The same subset $U$ is \textbf{convex} if every straight line segment between any two points in $U$ are in $U$.\marginnote{So a star shape would be star-like but not convex, because there a centre point can be reached by any other point, but two points on two different arms are not joined by a single straight line. A ball would be convex (and also star-like).}

\begin{lemma}[Poincar\'e's lemma]
  For $U \subset \mathbb{R}^n$ that is star-like, a closed $\omega \in \Omega^1(U) $ implies $\omega$ is exact. \qedwhite
\end{lemma}

For $U \subset \mathbb{R}^n$ open, $\boldsymbol{c}_{1,2} : [a, b] \to U$ be two curves with the same endpoints $\boldsymbol{x}, \boldsymbol{y} \in U$, then $\boldsymbol{c}_1$ and $\boldsymbol{c}_2$ are \textbf{homotopic} iff there exists some continuous $F: [a, b] \times [0, 1] \to U$ with\marginnote{Pictorially, two curves are homotopic if it can be deformed into another keeping the same end points.}
\begin{itemize}
  \item $F(s, 0) = \boldsymbol{c}_1(s)$, $F(s, 1) = \boldsymbol{c}_2(s)$ for all $s \in [a,b]$,
  \item $F(a, t) = \boldsymbol{x}$, $F(b,t) = \boldsymbol{y}$ for all $t \in [0, 1]$
\end{itemize}

\begin{corollary}
  If $\boldsymbol{c}_{1,2}$ are homotopic with the same end points, then by path equivalence we have
  \begin{equation}
    \omega \in \Omega^1(U)\textnormal{ closed}\quad \Leftrightarrow \quad \int_{\boldsymbol{c}_1} \omega = \int_{\boldsymbol{c}_2} \omega.
  \end{equation}
  \qedwhite
\end{corollary}

For $U \subset \mathbb{R}^n$ open, $\boldsymbol{c}_{1,2} : [a, b] \to U$ be closed curves. The $\boldsymbol{c}_{1,2}$ are \textbf{freely homotopic} if there is a continuous map $F: [a, b] \times [0, 1] \to U$ with
\begin{itemize}
  \item $F(s, 0) = \boldsymbol{c}_1(s)$, $F(s, 1) = \boldsymbol{c}_2(s)$ for all $s \in [a,b]$,
  \item $F(a, t) = F(b,t)$ for all $s \in [a,b]$ and $t \in [0, 1]$
\end{itemize}

\begin{corollary}
  For $U\subset \mathbb{R}^n$ and $\boldsymbol{c}_{1,2}$ are closed curves, $\omega \in \Omega^1(U)$ closed, then if $\boldsymbol{c}_{1,2}$ are freely homotopic, then
  \begin{equation*}
    \int_{\boldsymbol{c}_1} \omega = \int_{\boldsymbol{c}_2} \omega.
  \end{equation*}
  \qedwhite
\end{corollary}

%-------------------------------------------------------------------------------

\section{Differential $k$-forms}

\marginnote{\color{red}Notation consistent (?) up to here: roman are vectors, greek are forms. Move the notation note further up at some point.}

Recall that the determinant function
\begin{equation}
  \mbox{det} : \mathbb{R}^n \times \ldots \times \mathbb{R}^n = (\mathbb{R}^n)^n \to \mathbb{R}, \qquad (v_1, \ldots v_n) \to \mbox{det}[v_1, \ldots v_n],
\end{equation}
and that this function is multi-linear and alternating (to mean swapping any two entries introduces a minus sign in the output). 

Let $V$ be a real vector field of dimension $n$. An \textbf{alternating $k$-form} is a map $\alpha : V^k \to \mathbb{R}$ where $\alpha$ is multi-linear and alternating in all its entries. The set of all $k$-forms is denoted $\highlight{\Lambda^k(V)}$, which is a real vector space.

For $U\subset \mathbb{R}^n$ open, a map $\boldsymbol{\omega} : U \to \Lambda^k(\mathbb{R}^n)$ is a \textbf{differentiable $k$-form} if all the coefficient functions of $\boldsymbol{\omega}$
\begin{equation}
  f_{i_1, \ldots i_k}(\boldsymbol{p}) = \omega_p(\boldsymbol{e}_{i_1}, \ldots \boldsymbol{e}_{i_k})
\end{equation}
are smooth.

Note that since $\Lambda^1(\mathbb{R}^n) = \mathcal{L}(\mathbb{R}^n, \mathbb{R})$, differentiable 1-forms agree with the earlier definition. Also, if $\alpha \in \Lambda^k(V)$ is alternating, then if any $v_i = v_j$, we have $\alpha(v_1, \ldots v_k) = 0$ by the anti-symmetry property.

For a collection of 1-forms $\alpha_1, \ldots, \alpha_k \in \Lambda^1(V)$, the \textbf{wedge product} is defined as
\begin{equation}
  \highlight{\alpha_1 \wedge \ldots \wedge \alpha_k  \in \Lambda^k(V), \qquad \alpha_1 \wedge \ldots \wedge \alpha_k(v_1, \ldots v_k) = \mbox{det}(\alpha_i(v_j))}
\end{equation}
for all indices $i,j$ spanning from $1$ to $k$.\marginnote{Recalling that a 1-form eats a vector to get a number, and $(\alpha_i(v_j))$ are the entries of a matrix.} Note that elements of $\mathcal{L}(V, \mathbb{R})$ are elements of the dual space $V^*$ of linear forms on $V$. For every basis $\{v_1, \ldots, v_n\}$ of $V$ there is a dual basis $\{v_1^*, \ldots v_n^*\}$ of $V^*$ satisfying $v_i^* (v_j) = \delta_{ij}$.

\begin{proposition}
  A basis for $\Lambda^k(V)$ is the collection of $v_{i_1}^* \wedge \ldots \wedge v_{i_k}^* \in \Lambda^k(V)$ for strictly ascending indices, and where $\{v_1^*, \ldots v_n^*\}$ is a basis of $V^* = \mathcal{L}(V, \mathbb{R})$. Further, $\mbox{dim}\ \Lambda^k = {}^n C_k$ ($n$ choose $k$).
\end{proposition}

\begin{proof}
  We only need to consider wedge products of forms with strictly increasing indices because of the anti-symmetry property. Note that we have, by construction,
  \begin{equation*}
    v_{i_1}^* \wedge \ldots \wedge v_{i_k}^* (v_{j_1}, \ldots v_{j_k}) = \begin{cases}1, & i_m = j_m \\ 0, & \textnormal{otherwise}\end{cases},
  \end{equation*}
  so if
  \begin{equation*}
    \alpha = \sum (a_{i_1},\ldots a_{i_k})(v_{i_1}^* \wedge \ldots \wedge v_{i_k}^*) = 0
  \end{equation*}
  then this implies $a_{i_j} = 0$ for all $j$, and so $v_{i_1}^* \wedge \ldots \wedge v_{i_k}^*$ are linear independent if indices are strictly increasing.
  
  Let $\omega \in \Lambda^k(V)$ and consider the $k$-form
  \begin{equation*}
    \eta = \sum \omega(v_{i_1}, \ldots v_{i_k}) v_{i_1}^* \wedge \ldots \wedge v_{i_k}^*.
  \end{equation*}
  By construction, $\omega = \eta$ when being evaluate at all tuples $(v_{i_1}, \ldots v_{i_k})$ with increasing indices, and so all of $v_{i_1}^* \wedge \ldots \wedge v_{i_k}^*$ with increasing indices span $\Lambda^k(V)$, and thus we have a basis. \qed
\end{proof}

The wedge product operator extends naturally to alternating $k$-forms, since all $k$-forms can be expanded as a wedge product of 1-forms. It is also associative.

The set of differential $k$-forms on open $U\subset \mathbb{R}^n$ is denoted by $\highlight{\Omega^k(U)}$, which has a structure of a real vector space. The set of differential 0-forms is identified as $C^\infty(U)$. Then, we note that the wedge product is a map
\begin{equation}
  \wedge\ :\ \Omega^k(U) \times \Omega^l(U) \to \Omega^{k+l}(U).
\end{equation}
Note that wedging with $f\in C^\infty(U)$ gives $f\wedge \omega = f\omega$.

\begin{example}
  Let
  \begin{equation*}
    \omega = x\ \mathrm{d}x \wedge \mathrm{d}y + x^2 z\ \mathrm{d}y \wedge \mathrm{d}z \in \Omega^2(\mathbb{R}^3),
  \end{equation*}
  while
  \begin{equation*}
    \eta = z^2\ \mathrm{d}x + y^3\ \mathrm{d}y - \mathrm{d}z \in \Omega^1(\mathbb{R}^3).
  \end{equation*}
  We have that
  \begin{align*}
    \omega_{(1,0,0)}(e_1, e_2 + e_3) 
      &= (1\ \mathrm{d}x \wedge \mathrm{d}y + 0\ \mathrm{d}y \wedge \mathrm{d}z)(e_1, e_2 + e_3) \\
      &= \left|\begin{matrix}\mathrm{d}x\ e_1  & \mathrm{d}x\ (e_2 + e_3)\\ \mathrm{d}y\ e_1  & \mathrm{d}y\ (e_2 + e_3)\end{matrix}\right|\\
      &= \left|\begin{matrix}1  & 0 + 0\\ 0  & 1 + 0\end{matrix}\right| = 1.
  \end{align*}
  For $\omega\wedge\eta$, we note that the only result has to be a 3-form, and in $\mathbb{R}^3$ the basis 3-form is $\mathrm{d}x \wedge \mathrm{d}y \wedge \mathrm{d}z$ (since all others vanish by anti-symmetry, consistent with observation that $\mbox{dim}\ \Omega^3(\mathbb{R}^3) = {}^3C_3 = 1$), so we have
  \begin{equation*}
    \omega\wedge\eta = (-x + x^2 z^3)\ \mathrm{d}x \wedge \mathrm{d}y \wedge \mathrm{d}z.
  \end{equation*}
\end{example}

\begin{lemma}
 For $\omega \in \Omega^k(U)$ and $\eta \in \Omega^l(U)$, $\highlight{\omega \wedge \eta = (-1)^{k\cdot l}\ \eta \wedge \omega}.$
\end{lemma}

\begin{proof}
  By linearity, we only need to consider $\omega = f\ \mathrm{d}x_{i_1} \wedge \ldots \wedge \mathrm{d}x_{i_k}$ and $\eta = g\ \mathrm{d}x_{j_1} \wedge \ldots \wedge \mathrm{d}x_{j_l}$ with no overlapping indices (since then $\omega \wedge \eta = \eta \wedge \omega = 0$ by definition). \marginnote{Note the ordering in the second line requires $k$ swaps, and there are $l$ of them to do in the third line.}In that case,
  \begin{align*}
    \omega \wedge \eta
      &= fg\ \mathrm{d}x_{i_1} \wedge \ldots \wedge \mathrm{d}x_{i_k} \wedge \mathrm{d}x_{j_1} \wedge \ldots \wedge \mathrm{d}x_{j_l} \\
      &= (-1)^k fg\ \mathrm{d}x_{j_1} \wedge \mathrm{d}x_{i_1} \wedge \ldots \wedge \mathrm{d}x_{i_k} \wedge \ldots \wedge \mathrm{d}x_{j_l} \\
      &= (-1)^{k\cdot l} fg\ \mathrm{d}x_{j_1} \wedge \ldots \wedge \mathrm{d}x_{j_l} \wedge \mathrm{d}x_{i_1} \wedge \ldots \wedge \mathrm{d}x_{i_k}\\
      &= (-1)^{k\cdot l} \eta \wedge \omega,
  \end{align*}
  as required. \qed
\end{proof}

Let $U \subset \mathbb{R}^n$ be open and $\omega \in \Omega^k(U)$ be given by
\begin{equation*}
  \omega = \sum (f_{i_1}, \ldots f_{i_k})\ \mathrm{d}x_{i_1} \wedge \ldots \wedge \mathrm{d}x_{i_k}.
\end{equation*}
The \textbf{exterior derivative} of $\omega$ is given by
\begin{equation}
  \highlight{\mathrm{d}\omega = \sum \mathrm{d}(f_{i_1}, \ldots f_{i_k}) \wedge \mathrm{d}x_{i_1} \wedge \ldots \wedge \mathrm{d}x_{i_k} \in \Omega^{k+1}(U)}.
\end{equation}
This could be seen as an extension of the ordinary differential $\mathrm{d}f$ when $f \in C^\infty (U) = \Omega^0(U)$.

\begin{example}
  Let $\omega = xyz\ \mathrm{d}x + yz\ \mathrm{d}y + (x+z)\ \mathrm{d}z$. We have
  \begin{align*}
    \mathrm{d}\omega 
      &= (yz\ \mathrm{d}x + xz\ \mathrm{d}y + xy\ \mathrm{d}z) \wedge \mathrm{d}x \\
      & \qquad + (z\ \mathrm{d}y + y\ \mathrm{d}z)\wedge \mathrm{d}y + (\mathrm{d}x + \mathrm{d}z)\wedge \mathrm{d}z\\
      &= (-xz)\ \mathrm{d}x \wedge \mathrm{d}y + (1-xy)\ \mathrm{d}x \wedge \mathrm{d}z - y\ \mathrm{d}y \wedge \mathrm{d}z
  \end{align*}
  after collecting terms accordingly. Since $\omega$ is a 1-form, $\mathrm{d}\omega$ is correctly a 2-form as it should be.
\end{example}

\begin{example}
  For $\omega = f_i\ \mathrm{d}x_i$ on $U\subset \mathbb{R}^n$, since $\mathrm{d}f_i = \partial f_i / \partial x_j\ \mathrm{d}x_j$, we have
  \begin{equation}
    \mathrm{d}\omega = \frac{\partial f_i}{\partial x_j}\ \mathrm{d}x_j \wedge \mathrm{d}x_i = \sum_{k<l} \left(\frac{\partial f_k}{\partial x_l} - \frac{\partial f_l}{\partial x_k} \right)\ \mathrm{d}x_l \wedge \mathrm{d}x_k.
  \end{equation}
\end{example}

Note that $\mathrm{d}\omega = 0$ iff $\omega$ is closed, and since every exact 1-form is closed, we have $\mathrm{d}(\mathrm{d}f) = 0$ for all $f \in C^\infty(U)$ where $\mathrm{d}f = \omega$.

\begin{proposition}
  For $\omega, \eta \in \Omega^k(U)$, the exterior derivative $\mathrm{d}\ :\ \Omega^k(U) \to \Omega^{k+1}(U)$ has the following properties:
  \begin{enumerate}
    \item For $\lambda, \mu \in \mathbb{R}$, we have linearity where
    \begin{equation}
      \highlight{\mathrm{d}(\lambda \omega + \mu \eta) = \lambda\ \mathrm{d}\omega + \mu\ \mathrm{d}\eta}.
    \end{equation}
    
    \item We have the (graded) product rule
    \begin{equation}
      \highlight{\mathrm{d}(\omega \wedge \eta) = \mathrm{d}\omega \wedge \eta + (-1)^k\ \omega \wedge \mathrm{d}\eta}.
    \end{equation}
    
    \item $\highlight{\mathrm{d}(\mathrm{d}\omega) = 0}$\sidenote{This is a useful property for defining \textbf{de Rham cohomology}.}
  \end{enumerate}
\end{proposition}

\begin{proof}
  \begin{enumerate}
    \item By definition.
    
    \item By linearity, we only need to prove this for $\omega = \sum_i f\ \mathrm{d}x_{i_1} \wedge \ldots \wedge \mathrm{d}x_{i_k} = f\ \mathrm{d}x_I$ and $\eta = \sum_j g\ \mathrm{d}x_{j_1} \wedge \ldots \wedge \mathrm{d}x_{j_l} = g\ \mathrm{d}x_J$,
    \begin{align*}
      \mathrm{d}(\omega \wedge \eta) 
        &= \mathrm{d}(fg)\ \mathrm{d}x_I \wedge \mathrm{d}x_J \\
        &= g\ \mathrm{d}f \wedge \mathrm{d}x_I \wedge \mathrm{d}x_J + f\ \mathrm{d}g \wedge \mathrm{d}x_I \wedge \mathrm{d}x_J\\
        &= \mathrm{d}f \wedge \mathrm{d}x_I \wedge g\ \mathrm{d}x_J + (-1)^k f\ \mathrm{d}x_I \wedge \mathrm{d}g \wedge \mathrm{d}x_J\\
        &= \mathrm{d}(f\ \mathrm{d}x_I) \wedge \eta + (-1)^k\ \omega \wedge \mathrm{d}(g\ \mathrm{d}x_J)\\
        &= \mathrm{d}\omega \wedge \eta + (-1)^k\ \omega \wedge \mathrm{d}\eta,
    \end{align*}
    with appropriate uses of the reverse product rule.
    
    \item We have, noting that we must have $\mathrm{d}^2 f = 0$ and $\mathrm{d}(1) = 0$,
    \begin{align*}
      \mathrm{d}^2 (\omega \wedge \eta) 
        &= \mathrm{d}(\mathrm{d}f \wedge \mathrm{d}x_I)\\
        &= \mathrm{d}^2 f \wedge \mathrm{d}x_I - \mathrm{d}f \wedge \mathrm{d}^2 x_I\\
        &= -\mathrm{d}f \wedge \mathrm{d}(1\ \mathrm{d}x_I)\\
        &= -\mathrm{d}f \wedge d(1) \wedge \mathrm{d}x_I = 0.
    \end{align*}
    \qed
  \end{enumerate}
\end{proof}

Just like for 1-forms, $\omega \in \Omega^k(U)$ is \textbf{exact} if there exist some $\eta \in \Omega^{k+1}(U)$ where $\mathrm{d}\omega = \eta$. The $k$-form $\omega$ is \textbf{closed} if $\mathrm{d}\omega = 0$.

\begin{theorem}
  If $U \subset \mathbb{R}^n$ is open and star-like, then $\omega \in \Omega^k(U)$ closed iff $\omega$ is exact. \qedwhite.
\end{theorem}

Let $U \subset \mathbb{R}^n$ and $V \subset \mathbb{R}^m$ be open, and there is some smooth mapping $\phi\ :\ U \to V$. For $\omega \in \Omega^k(V)$, the \textbf{pullback} of $\omega$ with respect to $\phi$, denoted $\highlight{\phi^* \omega \in \Omega^k(U)}$ is defined as\marginnote{Note there are pullbacks of forms, but there is in general no pullbacks of vectors unless an inverse of $\phi$ is assumed. Pullback is akin to finding a Jacobian for doing integration when we do co-ordinate transformations.}
\begin{equation}
  \left.\phi^* \omega \right|_p (v_1, \ldots v_k) = \left.\omega\right|_{\phi(p)}\ (D\phi(p)(v_1), \ldots D\phi(p)(v_k))
\end{equation}
for all points $p\in U$, $(v_1, \ldots v_l) \in (\mathrm{R}^m)^k$.

\begin{proposition}
  For $U \subset \mathbb{R}^n$, $V \subset \mathbb{R}^m$ and smooth $\phi\ :\ U \to V$,
  \begin{enumerate}
    \item The pullback is linear, where for $\omega_{1,2} \in \Omega^k(V)$,
    \begin{equation}
      \highlight{\phi^* (\omega_1 + \omega_2) = \phi^* \omega_1 + \phi^* \omega_2}.
    \end{equation}
    
    \item For $f\in \Omega^0(V) = C^\infty(V)$ and $\omega \in \Omega^k(V)$,
    \begin{equation}
      \highlight{\phi^* (f\omega) = (\phi^* f) \circ (\phi^* \omega) = (f \circ \phi) \circ (\phi^* \omega)}.
    \end{equation}
    
    \item The appropriate chain rule with pullback of a 1-form is
    \begin{equation}
      \highlight{\phi^* (\mathrm{d}f) = \mathrm{d}(f \circ \phi) = \frac{\partial (f\circ\phi)}{\partial x_i}\ \mathrm{d}x_i}.
    \end{equation}
    
    \item For $\alpha_i \in \Omega^1(V)$, we have
    \begin{equation}
      \highlight{\phi^*(\alpha_1 \wedge \ldots \wedge \alpha_k) = \phi^* \alpha_1 \wedge \ldots \wedge \phi^* \alpha_k}.
    \end{equation}
  \end{enumerate}
\end{proposition}

\begin{proof}
  \begin{enumerate}
    \item By definition.
    
    \item Note that
    \begin{align*}
      \left.\phi^* (f\omega)\right|_p (v_1, \ldots, v_k) 
        &= \left.f\omega\right|_{\phi(p)}(D\phi(p) v_1, \ldots, D\phi(p) v_k)\\
        &= f(\phi(p)) \circ \left.\omega\right|_{\phi(p)}(D\phi(p) v_1, \ldots, D\phi(p) v_k)\\
        &= \left.(f \circ \phi)\right|_p \circ \left.\phi^*\omega\right|_{p}.
    \end{align*}
    
    \item Applying the standard chain rule in reverse, we have
    \begin{align*}
      \left.\phi^* (\mathrm{d}f)\right|_p v
        &= \left.\mathrm{d}f\right|_{\phi(p)}(D\phi(p) v)\\
        &= \left.Df\right|_{\phi(p)}(D\phi(p) v)\\
        &= \left.D(f \circ \phi)\right|_p (v)\\
        &= \left.\mathrm{d} (f \circ \phi)\right|_p (v).
    \end{align*}
    
    \item By definition,
    \begin{align*}
      \left.\phi^*(\alpha_1 \wedge \ldots \wedge \alpha_k)\right|_p (v_1, \ldots v_k) 
        &= (\alpha_1 \wedge \ldots \wedge \alpha_k) (D\phi(p) v_1, \ldots D\phi(p) v_k)\\
        &= \mbox{det}\left[
          \begin{matrix} 
            \left.\alpha_1\right|_{\phi(p)}(D\phi(p)v_1) & \ldots & \left.\alpha_1\right|_{\phi(p)}(D\phi(p)v_k) \\ 
            \vdots & \ddots & \vdots\\
            \left.\alpha_k\right|_{\phi(p)}(D\phi(p)v_1) & \ldots & \left.\alpha_k\right|_{\phi(p)}(D\phi(p)v_k)
          \end{matrix}\right]\\
        &= \mbox{det}\left[
          \begin{matrix} 
            \left.\phi^*\alpha_1\right|_{p}(v_1) & \ldots & \left.\phi^*\alpha_1\right|_{p}(v_k) \\ 
            \vdots & \ddots & \vdots\\
            \left.\phi^*\alpha_k\right|_{p}(v_1) & \ldots & \left.\phi^*\alpha_k\right|_{p}(v_k)
          \end{matrix}\right]\\
        &= \left.\phi^* \alpha_1 \wedge \ldots \wedge \phi^* \alpha_k\right|_{\phi(p)} (v_1, \ldots v_k).
    \end{align*}
  \end{enumerate}
  \qed
\end{proof}

Note that the last property generalises to $k$-forms. Also, if $\psi\ :\ V \to W$ is another map and now $\omega\in\Omega^k(W)$ (the end space), then the chain of pullbacks satisfy the usual function composition as $\phi^* (\psi^* \omega) = (\psi \circ \phi)^* \omega$.

\begin{example}
  To show that the pullback is akin to getting the Jacobian correction for integration when doing a co-ordinate transformation, start with the 2-form in Cartesian co-ordinates as $\omega = \mathrm{d}x \wedge \mathrm{d}y$. Transforming into polar co-ordinates, we use the map $\phi\ :\ (0,\infty) \times (0, 2\pi) \to \mathbb{R}^2$ with $(r,\theta) \mapsto (r\cos\theta, r\sin\theta)$. Then
  \begin{equation*}
    \phi^*(\mathrm{d}x = \mathrm{d}(x \circ \phi) = \mathrm{d}\phi_1 = \cos\theta\ \mathrm{d}r - r\sin\theta\ \mathrm{d}\theta,
  \end{equation*}
  since $x\circ\phi$ picks out the first component of $\phi = (r\cos\theta, r\sin\theta)$. Similarly,
  \begin{equation*}
    \phi^*(\mathrm{d}y = \mathrm{d}(y \circ \phi) = \mathrm{d}\phi_2 = \sin\theta\ \mathrm{d}r + r\cos\theta\ \mathrm{d}\theta,
  \end{equation*}
  and by linearity of pullbacks on the wedged forms,
  \begin{align*}
    \phi^* (\mathrm{d}x \wedge \mathrm{d}y)
      &= \phi^* \mathrm{d}x \wedge \phi^* \mathrm{d}y\\
      &= (\cos\theta\ \mathrm{d}r - r\sin\theta\ \mathrm{d}\theta) \wedge (\sin\theta\ \mathrm{d}r + r\cos\theta\ \mathrm{d}\theta)\\
      &= r\ \mathrm{d}r\wedge\mathrm{d}\theta,
  \end{align*}
  as expected.
\end{example}

\begin{proposition}
  The pullback is commutes with the exterior derivative: for $\omega \in \Omega^k(V)$ and $\phi\ :\ U \to V$,
  \begin{equation}
    \highlight{\mathrm{d}(\phi^*\omega) = \phi^*\mathrm{d}\omega}.
  \end{equation}
\end{proposition}

\begin{proof}
  By linearity, we only need to show it for $\omega = f\ \mathrm{d}x_I$. Let $\phi = (\phi_1, \ldots, \phi_m)$, so $\phi^*(\mathrm{d}x_j) = \mathrm{d}\phi_j$. Then
  \begin{align*}
    \mathrm{d}(\phi^*\omega) 
      &= \mathrm{d}(\phi^*(f\ \mathrm{d}x_I))\\
      &= \mathrm{d}((f\circ\phi) \mathrm{d}\phi_I)\\
      &= \mathrm{d}(f\circ\phi)\wedge \phi_I + (f\circ\phi) \mathrm{d}(\mathrm{d}\phi_I)
  \end{align*}
  by the definition of the exterior derivative (since $f\circ\phi$ is just a function), and the last term is zero since we have $\mathrm{d}^2=0$. Observe also that
  \begin{align*}
    \phi^(\mathrm{d}\omega) 
      &= \phi^*(\mathrm{d}f\wedge\ \mathrm{d}x_I + 0)\\
      &= \phi^*\mathrm{d}f \wedge \phi^*\mathrm{d}x_I\\
      &= \mathrm{d}(f\circ\phi) \wedge \mathrm{d}\phi_I
  \end{align*}
  by reverse chain rule, so we have commutativity between the exterior derivative and the pullback.
\end{proof}

Differential forms play an important role in integration, as will be demonstrated now.

%-------------------------------------------------------------------------------

\section{Integration in $\mathbb{R}^n$}

A subset $A \subset \mathbb{R}^n$ is of \textbf{measure zero} if, for all $\epsilon > 0$, there exists a countable set of rectangles $Q_i$ such that
\begin{equation*}
  A \subset \bigcup_{i=1} Q_i, \qquad \sum_i \mbox{vol}(Q_i) < \epsilon.
\end{equation*}

\begin{example}
  Let $A = \mathbb{R} \times \{0\} \subset \mathbb{R}^2$. Intuitively this has no area, which is the relevant measure in $\mathbb{R}^2$. Formally, define the rectangles as
  \begin{equation*}
    Q_i = [i-1, i+1] \times \left[-\frac{\epsilon}{2^{|i|}}, \frac{\epsilon}{2^{|i|}}\right], \qquad i\in \mathbb{Z},
  \end{equation*}
  which has area $2(2/2^{|i|})\epsilon$. $A$ is in the countably infinite union of the above rectangles, yet the area is (accounting for the symmetry of $|i|$ in the geometric sum)
  \begin{equation*}
    2\cdot 4 \epsilon \sum_{i=0}^\infty \frac{1}{2^i} = 12\epsilon,
  \end{equation*}
  which can me made arbitrarily small.
\end{example}

By similar arguments, every $k$-manifold in $\mathbb{R}^n$ with $k<n$ has measure zero.

\begin{proposition}
  \begin{enumerate}
    \item For $A \subset B \subset \mathbb{R}^n$, if $B$ has measure zero, then $A$ has measure zero.
    \item If all $A_i \subset \mathbb{R}^n$ has measure zero then their union also has measure zero.
    \item Rectangles $Q_i$ are not of measure zero.
  \end{enumerate}
  \qedwhite
\end{proposition}

\begin{theorem}
  Let $Q\subset \mathbb{R}^n$ be a rectangle and $f\ :\ Q \to \mathbb{R}$ be bounded. Then $f$ is Riemann integrable iff the set $D \subset Q$ of points in which $f$ is not continuous is of measure zero. \qedwhite
\end{theorem}

\begin{theorem}[Fubini's theorem]
  Let $f\ :\ Q \to \mathbb{R}$ be bounded and $Q = A \times B$. We write $f(x,y)$ for $x\in A$ and $y\in B$. For all $x$, we define
  \begin{equation*}
    f_x\ :\ B \to \mathbb{R}, \qquad f_x(y) = f(x,y).
  \end{equation*}
  Since $f_x$ is bounded, we consider $g, h\ :\ A\to\mathbb{R}$ defined as
  \begin{equation*}
    g(x) = \int_B^{\textnormal{lower}} f_x(y)\; \mathrm{d}y, \qquad h(x) = \int_B^{\textnormal{upper}} f_x(y)\; \mathrm{d}y.
  \end{equation*}
  If $f$ is integrable on $Q$, then $g, h$ are integrable over $A$, and\marginnote{It's really saying when can we pull integrals apart as
  \begin{align*}
    \int_Q f(x,y)\; \mathrm{d}Q 
      &= \int_A \int_B f(x,y)\; \mathrm{d}y\; \mathrm{d}x\\
      &= \int_B \int_A f(x,y)\; \mathrm{d}x\; \mathrm{d}y.
  \end{align*}
  This one is the weaker version of Fubini's theorem; there is a stronger one when $f$ is \textbf{Lebesque integrable}.}
  \begin{equation}
    \int_A g(x)\; \mathrm{d}x = \int_A h(x)\; \mathrm{d}x = \int_Q f\; \mathrm{d}x.
  \end{equation}
  \qedwhite.
\end{theorem}

Let $A \subset \mathbb{R}^n$ and $f\ :\ A \to \mathbb{R}$ be bounded. Let the \textbf{extension} of $f$ from $A \subset Q$ to $Q \subset \mathbb{R}^n$ where $Q$ is a rectangle be defined as
\begin{equation*}
  f_A\ :\ \mathbb{R}^n \to \mathbb{R}, \qquad f_A(x) = \begin{cases}f(x) & x \in A, \\ 0, & x \not\in A. \end{cases}
\end{equation*}
If $f$ is integrable, then $\int_A f\; \mathrm{d}x = \int_Q f_A\; \mathrm{d}x$.

\begin{proposition}[Transformation rule]\label{thm:transform}
  For $U, V\subset \mathbb{R}^n$ be open and bounded, $\phi\ :\ U\ to V$ be smooth, and $f\ :\ V \to \mathbb{R}$ integrable. then $f\circ\phi\ :\ U\to\mathbb{R}$ is integrable and\marginnote{Note the similarity of this with the pullback; see below.}
  \begin{equation}
    \highlight{\int_V f\; \mathrm{d}x = \int_U (f\circ\phi)\ |\mbox{det}\ D\phi|\; \mathrm{d}y}.
  \end{equation}
  \qedwhite
\end{proposition}

For open $U \subset \mathbb{R}$, and $\omega \in \Omega^n(U)$, we have
\begin{equation}
  \highlight{\int_U \omega = \int_U \omega(e_1, \ldots, e_n)}
\end{equation}
where $e_i$ are the basis vectors. In component form, we have
\begin{equation}
  \int_U \omega = \int_U f\; \mathrm{d}x_1 \wedge \ldots \wedge \mathrm{d}x_n = \int f(x)\; \mathrm{d}x.
\end{equation}

For the $\phi$ mapping above, $\phi\ :\ U \to V$ is \textbf{orientation preserving} if $\mbox{det}\ D\phi > 0$ for all $x \in U$, and is \textbf{orientation reversing} if $\mbox{det}\ D\phi > 0$.

\begin{proposition}
  For smooth $\phi\ :\ U \to V$ and $\omega \in \Omega^n(U)$, we have
  \begin{equation*}
    \int_V \omega = \pm \int_U \phi^*\omega
  \end{equation*}
  where we take the plus sign is $\phi$ is orientation preserving.
\end{proposition}

\begin{proof}
  Let $\phi = (\phi_1, \ldots \phi_n)$ and $\omega = f\; \mathrm{d}x_1 \wedge \ldots \wedge \mathrm{d}x_n$. Then
  \begin{align*}
    \phi^*\omega 
      &= (f\circ\phi)(\mathrm{d}\phi_1 \wedge \ldots \wedge \mathrm{d}\phi_n)\\
      &= (f\circ\phi)\left(\frac{\partial \phi_1}{\partial x_i}\mathrm{d}x_i \wedge \ldots \wedge \frac{\partial \phi_n}{\partial x_i}\mathrm{d}x_i\right)\\
      &= \sum_{\sigma\in S_n} (f\circ\phi) \left(\frac{\partial \phi_1}{\partial x_{\sigma(1)}} \cdots \frac{\partial \phi_n}{\partial x_{\sigma(n)}} \right)\mathrm{d}x_{\sigma(1)} \wedge \ldots \wedge \mathrm{d}x_{\sigma(n)}\\
      &= \sum_{\sigma\in S_n} (f\circ\phi) \mbox{sgn}(\sigma) \left(\frac{\partial \phi_1}{\partial x_{\sigma(1)}} \cdots \frac{\partial \phi_n}{\partial x_{\sigma(n)}} \right)\mathrm{d}x_1 \wedge \ldots \wedge \mathrm{d}x_n\\
      &= (f\circ\phi)\ \mbox{det}\ D\phi\ \mathrm{d}x_1 \wedge \ldots \wedge \mathrm{d}x_n,
  \end{align*}
  so
  \begin{equation*}
    \int_U \phi^*\omega = \int_U (f\circ\phi)\ \mbox{det}\ D\phi = \pm \int_V f\; \mathrm{d}x = \pm \int_V \omega
  \end{equation*}
  by the transformation rule (Proposition \ref{thm:transform}). \qed
\end{proof}

%===============================================================================

\chapter{Differential forms on oriented manifolds}

Let $M \subset \mathbb{R}^n$

%-------------------------------------------------------------------------------

\section{Stokes' theorem}

%===============================================================================

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% r.5 contents
%\tableofcontents

%\listoffigures

%\listoftables

% r.7 dedication
%\cleardoublepage
%~\vfill
%\begin{doublespace}
%\noindent\fontsize{18}{22}\selectfont\itshape
%\nohyphenation
%Dedicated to those who appreciate \LaTeX{} 
%and the work of \mbox{Edward R.~Tufte} 
%and \mbox{Donald E.~Knuth}.
%\end{doublespace}
%\vfill

% r.9 introduction
% \cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% actual useful crap (normal chapters)
\mainmatter

%\part{Basics (?)}


%\backmatter

%\bibliography{refs}
\bibliographystyle{plainnat}

%\printindex

\end{document}

